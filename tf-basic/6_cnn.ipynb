{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (畳み込みニューラルネットワーク)\n",
    "\n",
    "Convolution層(畳み込み層)、Pooling層（プーリング層)などの層が特徴的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import initializations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: (9216, 32, 32, 1) (9216, 72)\n",
      "cv set: (2304, 32, 32, 1) (2304, 72)\n"
     ]
    }
   ],
   "source": [
    "# 分類クラス数\n",
    "nb_classes = 72\n",
    "\n",
    "# データの読み込み\n",
    "ary = np.load(\"./../data/hiragana.npz\")['arr_0'].reshape([-1, 127, 128]).astype(np.float32) / 15\n",
    "ary.shape\n",
    "\n",
    "# 入力データの取得\n",
    "# サイズを変換する (127, 128) => (32, 32)\n",
    "img_height, img_width = 32, 32\n",
    "\n",
    "X_data = np.zeros([nb_classes * 160, img_height, img_width], dtype=np.float32)\n",
    "for i in range(nb_classes * 160):\n",
    "    # 画像をリサイズする\n",
    "    X_data[i] = scipy.misc.imresize(ary[i], (img_height, img_width), mode='F')\n",
    "Y_data = np.repeat(np.arange(nb_classes), 160)\n",
    "\n",
    "del ary\n",
    "\n",
    "# CNNに合わせるためにreshape\n",
    "# (11520, 32, 32) => (11520, 32, 32, 1)\n",
    "X_data = X_data.reshape(X_data.shape[0], img_height, img_width, 1)\n",
    "\n",
    "# データセットをトレーニングセットとCVに分ける（8:2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size=0.2)\n",
    "\n",
    "# one-hot vectorに変換する\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    y = np.array(y, dtype='int').ravel()\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, nb_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical\n",
    "\n",
    "Y_train0_old = Y_train[0]\n",
    "Y_train = to_categorical(Y_train, nb_classes)\n",
    "Y_val = to_categorical(Y_val, nb_classes)\n",
    "\n",
    "# 表示\n",
    "print('train set:', X_train.shape, Y_train.shape)\n",
    "print('cv set:', X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# カスタム初期化\n",
    "def custom_init(shape, name=None):\n",
    "    return initializations.normal(shape, scale=0.1, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# モデルの作成(VGG風)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, init=custom_init, input_shape=(32, 32, 1))) # filter数, filterの縦幅、filterの横幅\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3, init=custom_init))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, init=custom_init))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, init=custom_init))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, init=custom_init))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# エポック単位に自動的に重みを保存する\n",
    "checkpoint_collback = ModelCheckpoint(\n",
    "    filepath='/tmp/model.hdf5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EarlyStopping: patience回連続でコストの最小値が更新されない場合ストップ\n",
    "early_stop = EarlyStopping(patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 最適化とコスト\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adadelta',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataAugumentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.20)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "9216/9216 [==============================] - 66s - loss: 4.2371 - acc: 0.0255 - val_loss: 4.0681 - val_acc: 0.0916\n",
      "Epoch 2/500\n",
      "9216/9216 [==============================] - 84s - loss: 3.8963 - acc: 0.0756 - val_loss: 3.2908 - val_acc: 0.3411\n",
      "Epoch 3/500\n",
      "9216/9216 [==============================] - 79s - loss: 3.3768 - acc: 0.1553 - val_loss: 2.3864 - val_acc: 0.5191\n",
      "Epoch 4/500\n",
      "9216/9216 [==============================] - 62s - loss: 2.8581 - acc: 0.2451 - val_loss: 1.8336 - val_acc: 0.6202\n",
      "Epoch 5/500\n",
      "9216/9216 [==============================] - 61s - loss: 2.4647 - acc: 0.3264 - val_loss: 1.4134 - val_acc: 0.6940\n",
      "Epoch 6/500\n",
      "9216/9216 [==============================] - 61s - loss: 2.1775 - acc: 0.3867 - val_loss: 1.1478 - val_acc: 0.7439\n",
      "Epoch 7/500\n",
      "9216/9216 [==============================] - 61s - loss: 1.9308 - acc: 0.4425 - val_loss: 0.9736 - val_acc: 0.7626\n",
      "Epoch 8/500\n",
      "9216/9216 [==============================] - 61s - loss: 1.7203 - acc: 0.4974 - val_loss: 0.7585 - val_acc: 0.8069\n",
      "Epoch 9/500\n",
      "9216/9216 [==============================] - 62s - loss: 1.5406 - acc: 0.5347 - val_loss: 0.6314 - val_acc: 0.8281\n",
      "Epoch 10/500\n",
      "9216/9216 [==============================] - 61s - loss: 1.4001 - acc: 0.5788 - val_loss: 0.5590 - val_acc: 0.8459\n",
      "Epoch 11/500\n",
      "9216/9216 [==============================] - 63s - loss: 1.3187 - acc: 0.6028 - val_loss: 0.5368 - val_acc: 0.8442\n",
      "Epoch 12/500\n",
      "9216/9216 [==============================] - 63s - loss: 1.1918 - acc: 0.6331 - val_loss: 0.4567 - val_acc: 0.8711\n",
      "Epoch 13/500\n",
      "9216/9216 [==============================] - 62s - loss: 1.1195 - acc: 0.6500 - val_loss: 0.4084 - val_acc: 0.8854\n",
      "Epoch 14/500\n",
      "9216/9216 [==============================] - 60s - loss: 1.0426 - acc: 0.6744 - val_loss: 0.3722 - val_acc: 0.8902\n",
      "Epoch 15/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.9575 - acc: 0.7005 - val_loss: 0.3338 - val_acc: 0.9006\n",
      "Epoch 16/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.9133 - acc: 0.7082 - val_loss: 0.3212 - val_acc: 0.9049\n",
      "Epoch 17/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.8740 - acc: 0.7268 - val_loss: 0.3099 - val_acc: 0.9119\n",
      "Epoch 18/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.8381 - acc: 0.7343 - val_loss: 0.2743 - val_acc: 0.9223\n",
      "Epoch 19/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.7859 - acc: 0.7507 - val_loss: 0.2642 - val_acc: 0.9240\n",
      "Epoch 20/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.7525 - acc: 0.7603 - val_loss: 0.2417 - val_acc: 0.9288\n",
      "Epoch 21/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.7170 - acc: 0.7687 - val_loss: 0.2226 - val_acc: 0.9349\n",
      "Epoch 22/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.6658 - acc: 0.7867 - val_loss: 0.2088 - val_acc: 0.9423\n",
      "Epoch 23/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.6492 - acc: 0.7945 - val_loss: 0.1952 - val_acc: 0.9436\n",
      "Epoch 24/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.6158 - acc: 0.8001 - val_loss: 0.1808 - val_acc: 0.9453\n",
      "Epoch 25/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.5991 - acc: 0.8047 - val_loss: 0.1718 - val_acc: 0.9501\n",
      "Epoch 26/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.5829 - acc: 0.8127 - val_loss: 0.1654 - val_acc: 0.9492\n",
      "Epoch 27/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.5475 - acc: 0.8189 - val_loss: 0.1645 - val_acc: 0.9523\n",
      "Epoch 28/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.5383 - acc: 0.8276 - val_loss: 0.1585 - val_acc: 0.9570\n",
      "Epoch 29/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.5194 - acc: 0.8324 - val_loss: 0.1393 - val_acc: 0.9640\n",
      "Epoch 30/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.5161 - acc: 0.8327 - val_loss: 0.1360 - val_acc: 0.9644\n",
      "Epoch 31/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.4951 - acc: 0.8426 - val_loss: 0.1282 - val_acc: 0.9653\n",
      "Epoch 32/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.4874 - acc: 0.8433 - val_loss: 0.1245 - val_acc: 0.9666\n",
      "Epoch 33/500\n",
      "9216/9216 [==============================] - 59s - loss: 0.4494 - acc: 0.8567 - val_loss: 0.1141 - val_acc: 0.9674\n",
      "Epoch 34/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.4496 - acc: 0.8561 - val_loss: 0.1107 - val_acc: 0.9666\n",
      "Epoch 35/500\n",
      "9216/9216 [==============================] - 59s - loss: 0.4382 - acc: 0.8590 - val_loss: 0.1108 - val_acc: 0.9661\n",
      "Epoch 36/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.4317 - acc: 0.8602 - val_loss: 0.1049 - val_acc: 0.9696\n",
      "Epoch 37/500\n",
      "9216/9216 [==============================] - 59s - loss: 0.4139 - acc: 0.8670 - val_loss: 0.1015 - val_acc: 0.9683\n",
      "Epoch 38/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.4324 - acc: 0.8647 - val_loss: 0.1018 - val_acc: 0.9705\n",
      "Epoch 39/500\n",
      "9216/9216 [==============================] - 59s - loss: 0.4096 - acc: 0.8708 - val_loss: 0.0910 - val_acc: 0.9722\n",
      "Epoch 40/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.3968 - acc: 0.8750 - val_loss: 0.0947 - val_acc: 0.9727\n",
      "Epoch 41/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3812 - acc: 0.8764 - val_loss: 0.0956 - val_acc: 0.9692\n",
      "Epoch 42/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.3709 - acc: 0.8827 - val_loss: 0.0929 - val_acc: 0.9696\n",
      "Epoch 43/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3706 - acc: 0.8837 - val_loss: 0.0821 - val_acc: 0.9770\n",
      "Epoch 44/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3564 - acc: 0.8879 - val_loss: 0.0854 - val_acc: 0.9714\n",
      "Epoch 45/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3562 - acc: 0.8885 - val_loss: 0.0835 - val_acc: 0.9735\n",
      "Epoch 46/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3495 - acc: 0.8882 - val_loss: 0.0770 - val_acc: 0.9770\n",
      "Epoch 47/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3390 - acc: 0.8918 - val_loss: 0.0766 - val_acc: 0.9757\n",
      "Epoch 48/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.3346 - acc: 0.8963 - val_loss: 0.0762 - val_acc: 0.9757\n",
      "Epoch 49/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3252 - acc: 0.8943 - val_loss: 0.0742 - val_acc: 0.9757\n",
      "Epoch 50/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3288 - acc: 0.8928 - val_loss: 0.0650 - val_acc: 0.9783\n",
      "Epoch 51/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3212 - acc: 0.8992 - val_loss: 0.0659 - val_acc: 0.9787\n",
      "Epoch 52/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.3106 - acc: 0.8990 - val_loss: 0.0641 - val_acc: 0.9805\n",
      "Epoch 53/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.3133 - acc: 0.8987 - val_loss: 0.0678 - val_acc: 0.9753\n",
      "Epoch 54/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.3198 - acc: 0.8956 - val_loss: 0.0637 - val_acc: 0.9783\n",
      "Epoch 55/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.2977 - acc: 0.9077 - val_loss: 0.0571 - val_acc: 0.9800\n",
      "Epoch 56/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2929 - acc: 0.9046 - val_loss: 0.0596 - val_acc: 0.9805\n",
      "Epoch 57/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.2862 - acc: 0.9091 - val_loss: 0.0675 - val_acc: 0.9779\n",
      "Epoch 58/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2808 - acc: 0.9084 - val_loss: 0.0549 - val_acc: 0.9805\n",
      "Epoch 59/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.2810 - acc: 0.9092 - val_loss: 0.0550 - val_acc: 0.9826\n",
      "Epoch 60/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2831 - acc: 0.9049 - val_loss: 0.0548 - val_acc: 0.9805\n",
      "Epoch 61/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.2828 - acc: 0.9120 - val_loss: 0.0596 - val_acc: 0.9800\n",
      "Epoch 62/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2801 - acc: 0.9113 - val_loss: 0.0548 - val_acc: 0.9826\n",
      "Epoch 63/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.2776 - acc: 0.9108 - val_loss: 0.0538 - val_acc: 0.9826\n",
      "Epoch 64/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2563 - acc: 0.9188 - val_loss: 0.0532 - val_acc: 0.9831\n",
      "Epoch 65/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2756 - acc: 0.9128 - val_loss: 0.0538 - val_acc: 0.9805\n",
      "Epoch 66/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.2631 - acc: 0.9148 - val_loss: 0.0523 - val_acc: 0.9809\n",
      "Epoch 67/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2540 - acc: 0.9207 - val_loss: 0.0534 - val_acc: 0.9831\n",
      "Epoch 68/500\n",
      "9216/9216 [==============================] - 60s - loss: 0.2622 - acc: 0.9151 - val_loss: 0.0500 - val_acc: 0.9839\n",
      "Epoch 69/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2499 - acc: 0.9239 - val_loss: 0.0500 - val_acc: 0.9839\n",
      "Epoch 70/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2527 - acc: 0.9207 - val_loss: 0.0534 - val_acc: 0.9813\n",
      "Epoch 71/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2467 - acc: 0.9200 - val_loss: 0.0470 - val_acc: 0.9844\n",
      "Epoch 72/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2434 - acc: 0.9229 - val_loss: 0.0483 - val_acc: 0.9844\n",
      "Epoch 73/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2457 - acc: 0.9208 - val_loss: 0.0566 - val_acc: 0.9805\n",
      "Epoch 74/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2389 - acc: 0.9244 - val_loss: 0.0453 - val_acc: 0.9844\n",
      "Epoch 75/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2273 - acc: 0.9288 - val_loss: 0.0428 - val_acc: 0.9857\n",
      "Epoch 76/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2298 - acc: 0.9262 - val_loss: 0.0443 - val_acc: 0.9852\n",
      "Epoch 77/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2359 - acc: 0.9262 - val_loss: 0.0430 - val_acc: 0.9857\n",
      "Epoch 78/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2337 - acc: 0.9294 - val_loss: 0.0439 - val_acc: 0.9848\n",
      "Epoch 79/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2339 - acc: 0.9264 - val_loss: 0.0430 - val_acc: 0.9857\n",
      "Epoch 80/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2349 - acc: 0.9253 - val_loss: 0.0402 - val_acc: 0.9874\n",
      "Epoch 81/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.2252 - acc: 0.9297 - val_loss: 0.0396 - val_acc: 0.9865\n",
      "Epoch 82/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2279 - acc: 0.9245 - val_loss: 0.0376 - val_acc: 0.9861\n",
      "Epoch 83/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2283 - acc: 0.9245 - val_loss: 0.0400 - val_acc: 0.9878\n",
      "Epoch 84/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2175 - acc: 0.9294 - val_loss: 0.0423 - val_acc: 0.9874\n",
      "Epoch 85/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2271 - acc: 0.9259 - val_loss: 0.0353 - val_acc: 0.9878\n",
      "Epoch 86/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2180 - acc: 0.9293 - val_loss: 0.0370 - val_acc: 0.9878\n",
      "Epoch 87/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2205 - acc: 0.9316 - val_loss: 0.0343 - val_acc: 0.9896\n",
      "Epoch 88/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2115 - acc: 0.9341 - val_loss: 0.0396 - val_acc: 0.9861\n",
      "Epoch 89/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2084 - acc: 0.9335 - val_loss: 0.0389 - val_acc: 0.9865\n",
      "Epoch 90/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2096 - acc: 0.9333 - val_loss: 0.0331 - val_acc: 0.9891\n",
      "Epoch 91/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.2069 - acc: 0.9328 - val_loss: 0.0359 - val_acc: 0.9861\n",
      "Epoch 92/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2148 - acc: 0.9359 - val_loss: 0.0362 - val_acc: 0.9891\n",
      "Epoch 93/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2088 - acc: 0.9321 - val_loss: 0.0359 - val_acc: 0.9878\n",
      "Epoch 94/500\n",
      "9216/9216 [==============================] - 61s - loss: 0.2150 - acc: 0.9310 - val_loss: 0.0343 - val_acc: 0.9896\n",
      "Epoch 95/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2082 - acc: 0.9323 - val_loss: 0.0356 - val_acc: 0.9857\n",
      "Epoch 96/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1983 - acc: 0.9360 - val_loss: 0.0317 - val_acc: 0.9891\n",
      "Epoch 97/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2074 - acc: 0.9352 - val_loss: 0.0297 - val_acc: 0.9900\n",
      "Epoch 98/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.2013 - acc: 0.9358 - val_loss: 0.0330 - val_acc: 0.9883\n",
      "Epoch 99/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1923 - acc: 0.9389 - val_loss: 0.0363 - val_acc: 0.9870\n",
      "Epoch 100/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1998 - acc: 0.9380 - val_loss: 0.0329 - val_acc: 0.9896\n",
      "Epoch 101/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1952 - acc: 0.9383 - val_loss: 0.0348 - val_acc: 0.9887\n",
      "Epoch 102/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1855 - acc: 0.9386 - val_loss: 0.0326 - val_acc: 0.9887\n",
      "Epoch 103/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.2010 - acc: 0.9375 - val_loss: 0.0345 - val_acc: 0.9883\n",
      "Epoch 104/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1843 - acc: 0.9382 - val_loss: 0.0314 - val_acc: 0.9883\n",
      "Epoch 105/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1931 - acc: 0.9401 - val_loss: 0.0302 - val_acc: 0.9905\n",
      "Epoch 106/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1947 - acc: 0.9406 - val_loss: 0.0329 - val_acc: 0.9883\n",
      "Epoch 107/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1959 - acc: 0.9392 - val_loss: 0.0374 - val_acc: 0.9891\n",
      "Epoch 108/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1907 - acc: 0.9386 - val_loss: 0.0323 - val_acc: 0.9896\n",
      "Epoch 109/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1834 - acc: 0.9387 - val_loss: 0.0342 - val_acc: 0.9887\n",
      "Epoch 110/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1819 - acc: 0.9437 - val_loss: 0.0280 - val_acc: 0.9909\n",
      "Epoch 111/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1783 - acc: 0.9442 - val_loss: 0.0335 - val_acc: 0.9896\n",
      "Epoch 112/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1819 - acc: 0.9437 - val_loss: 0.0310 - val_acc: 0.9905\n",
      "Epoch 113/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1793 - acc: 0.9449 - val_loss: 0.0271 - val_acc: 0.9905\n",
      "Epoch 114/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1779 - acc: 0.9422 - val_loss: 0.0311 - val_acc: 0.9887\n",
      "Epoch 115/500\n",
      "9216/9216 [==============================] - 62s - loss: 0.1765 - acc: 0.9444 - val_loss: 0.0306 - val_acc: 0.9900\n",
      "Epoch 116/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1835 - acc: 0.9428 - val_loss: 0.0276 - val_acc: 0.9905\n",
      "Epoch 117/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1813 - acc: 0.9438 - val_loss: 0.0300 - val_acc: 0.9905\n",
      "Epoch 118/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1767 - acc: 0.9419 - val_loss: 0.0292 - val_acc: 0.9913\n",
      "Epoch 119/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1869 - acc: 0.9414 - val_loss: 0.0279 - val_acc: 0.9922\n",
      "Epoch 120/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1786 - acc: 0.9424 - val_loss: 0.0286 - val_acc: 0.9900\n",
      "Epoch 121/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1788 - acc: 0.9423 - val_loss: 0.0286 - val_acc: 0.9931\n",
      "Epoch 122/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1913 - acc: 0.9404 - val_loss: 0.0299 - val_acc: 0.9913\n",
      "Epoch 123/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1856 - acc: 0.9443 - val_loss: 0.0287 - val_acc: 0.9913\n",
      "Epoch 124/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1755 - acc: 0.9451 - val_loss: 0.0295 - val_acc: 0.9913\n",
      "Epoch 125/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1728 - acc: 0.9479 - val_loss: 0.0299 - val_acc: 0.9918\n",
      "Epoch 126/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1743 - acc: 0.9469 - val_loss: 0.0269 - val_acc: 0.9900\n",
      "Epoch 127/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1790 - acc: 0.9431 - val_loss: 0.0259 - val_acc: 0.9913\n",
      "Epoch 128/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1735 - acc: 0.9444 - val_loss: 0.0286 - val_acc: 0.9913\n",
      "Epoch 129/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1675 - acc: 0.9469 - val_loss: 0.0280 - val_acc: 0.9900\n",
      "Epoch 130/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1746 - acc: 0.9446 - val_loss: 0.0305 - val_acc: 0.9905\n",
      "Epoch 131/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1706 - acc: 0.9450 - val_loss: 0.0287 - val_acc: 0.9900\n",
      "Epoch 132/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1670 - acc: 0.9429 - val_loss: 0.0258 - val_acc: 0.9913\n",
      "Epoch 133/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1647 - acc: 0.9475 - val_loss: 0.0286 - val_acc: 0.9900\n",
      "Epoch 134/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1676 - acc: 0.9456 - val_loss: 0.0259 - val_acc: 0.9918\n",
      "Epoch 135/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1756 - acc: 0.9455 - val_loss: 0.0256 - val_acc: 0.9918\n",
      "Epoch 136/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1693 - acc: 0.9450 - val_loss: 0.0279 - val_acc: 0.9918\n",
      "Epoch 137/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1689 - acc: 0.9475 - val_loss: 0.0261 - val_acc: 0.9909\n",
      "Epoch 138/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1681 - acc: 0.9446 - val_loss: 0.0305 - val_acc: 0.9905\n",
      "Epoch 139/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1709 - acc: 0.9461 - val_loss: 0.0264 - val_acc: 0.9909\n",
      "Epoch 140/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1674 - acc: 0.9489 - val_loss: 0.0300 - val_acc: 0.9883\n",
      "Epoch 141/500\n",
      "9216/9216 [==============================] - 63s - loss: 0.1577 - acc: 0.9516 - val_loss: 0.0281 - val_acc: 0.9900\n",
      "Epoch 142/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1647 - acc: 0.9463 - val_loss: 0.0293 - val_acc: 0.9913\n",
      "Epoch 143/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1743 - acc: 0.9450 - val_loss: 0.0278 - val_acc: 0.9926\n",
      "Epoch 144/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1600 - acc: 0.9525 - val_loss: 0.0243 - val_acc: 0.9926\n",
      "Epoch 145/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1700 - acc: 0.9478 - val_loss: 0.0301 - val_acc: 0.9891\n",
      "Epoch 146/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1553 - acc: 0.9500 - val_loss: 0.0261 - val_acc: 0.9905\n",
      "Epoch 147/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1658 - acc: 0.9484 - val_loss: 0.0257 - val_acc: 0.9918\n",
      "Epoch 148/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1561 - acc: 0.9531 - val_loss: 0.0286 - val_acc: 0.9900\n",
      "Epoch 149/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1606 - acc: 0.9505 - val_loss: 0.0317 - val_acc: 0.9891\n",
      "Epoch 150/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1658 - acc: 0.9461 - val_loss: 0.0267 - val_acc: 0.9922\n",
      "Epoch 151/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1725 - acc: 0.9449 - val_loss: 0.0268 - val_acc: 0.9905\n",
      "Epoch 152/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1566 - acc: 0.9486 - val_loss: 0.0262 - val_acc: 0.9922\n",
      "Epoch 153/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1598 - acc: 0.9466 - val_loss: 0.0241 - val_acc: 0.9926\n",
      "Epoch 154/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1564 - acc: 0.9473 - val_loss: 0.0262 - val_acc: 0.9918\n",
      "Epoch 155/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1522 - acc: 0.9528 - val_loss: 0.0240 - val_acc: 0.9905\n",
      "Epoch 156/500\n",
      "9216/9216 [==============================] - 64s - loss: 0.1595 - acc: 0.9482 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "Epoch 157/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1440 - acc: 0.9542 - val_loss: 0.0247 - val_acc: 0.9926\n",
      "Epoch 158/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1522 - acc: 0.9517 - val_loss: 0.0257 - val_acc: 0.9913\n",
      "Epoch 159/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1585 - acc: 0.9501 - val_loss: 0.0262 - val_acc: 0.9931\n",
      "Epoch 160/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1528 - acc: 0.9487 - val_loss: 0.0256 - val_acc: 0.9905\n",
      "Epoch 161/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1521 - acc: 0.9545 - val_loss: 0.0248 - val_acc: 0.9935\n",
      "Epoch 162/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1599 - acc: 0.9486 - val_loss: 0.0253 - val_acc: 0.9913\n",
      "Epoch 163/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1491 - acc: 0.9529 - val_loss: 0.0248 - val_acc: 0.9926\n",
      "Epoch 164/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1457 - acc: 0.9536 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "Epoch 165/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1638 - acc: 0.9504 - val_loss: 0.0261 - val_acc: 0.9913\n",
      "Epoch 166/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1655 - acc: 0.9485 - val_loss: 0.0277 - val_acc: 0.9913\n",
      "Epoch 167/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1584 - acc: 0.9507 - val_loss: 0.0253 - val_acc: 0.9913\n",
      "Epoch 168/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1676 - acc: 0.9485 - val_loss: 0.0260 - val_acc: 0.9931\n",
      "Epoch 169/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1518 - acc: 0.9503 - val_loss: 0.0233 - val_acc: 0.9909\n",
      "Epoch 170/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1568 - acc: 0.9490 - val_loss: 0.0251 - val_acc: 0.9918\n",
      "Epoch 171/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1557 - acc: 0.9518 - val_loss: 0.0254 - val_acc: 0.9922\n",
      "Epoch 172/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1428 - acc: 0.9539 - val_loss: 0.0249 - val_acc: 0.9922\n",
      "Epoch 173/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1613 - acc: 0.9524 - val_loss: 0.0276 - val_acc: 0.9913\n",
      "Epoch 174/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1592 - acc: 0.9502 - val_loss: 0.0244 - val_acc: 0.9913\n",
      "Epoch 175/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1507 - acc: 0.9543 - val_loss: 0.0228 - val_acc: 0.9913\n",
      "Epoch 176/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1504 - acc: 0.9504 - val_loss: 0.0263 - val_acc: 0.9922\n",
      "Epoch 177/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1530 - acc: 0.9520 - val_loss: 0.0268 - val_acc: 0.9918\n",
      "Epoch 178/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1412 - acc: 0.9544 - val_loss: 0.0260 - val_acc: 0.9922\n",
      "Epoch 179/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1457 - acc: 0.9545 - val_loss: 0.0233 - val_acc: 0.9926\n",
      "Epoch 180/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1531 - acc: 0.9529 - val_loss: 0.0224 - val_acc: 0.9926\n",
      "Epoch 181/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1531 - acc: 0.9503 - val_loss: 0.0228 - val_acc: 0.9922\n",
      "Epoch 182/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1574 - acc: 0.9518 - val_loss: 0.0229 - val_acc: 0.9939\n",
      "Epoch 183/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1484 - acc: 0.9513 - val_loss: 0.0218 - val_acc: 0.9931\n",
      "Epoch 184/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1386 - acc: 0.9564 - val_loss: 0.0237 - val_acc: 0.9926\n",
      "Epoch 185/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1564 - acc: 0.9525 - val_loss: 0.0246 - val_acc: 0.9926\n",
      "Epoch 186/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1551 - acc: 0.9513 - val_loss: 0.0227 - val_acc: 0.9935\n",
      "Epoch 187/500\n",
      "9216/9216 [==============================] - 65s - loss: 0.1544 - acc: 0.9537 - val_loss: 0.0233 - val_acc: 0.9918\n",
      "Epoch 188/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1483 - acc: 0.9550 - val_loss: 0.0250 - val_acc: 0.9918\n",
      "Epoch 189/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1421 - acc: 0.9545 - val_loss: 0.0224 - val_acc: 0.9926\n",
      "Epoch 190/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1545 - acc: 0.9553 - val_loss: 0.0276 - val_acc: 0.9913\n",
      "Epoch 191/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1441 - acc: 0.9544 - val_loss: 0.0236 - val_acc: 0.9926\n",
      "Epoch 192/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1336 - acc: 0.9570 - val_loss: 0.0235 - val_acc: 0.9913\n",
      "Epoch 193/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1527 - acc: 0.9532 - val_loss: 0.0248 - val_acc: 0.9922\n",
      "Epoch 194/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1428 - acc: 0.9559 - val_loss: 0.0237 - val_acc: 0.9909\n",
      "Epoch 195/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1533 - acc: 0.9490 - val_loss: 0.0282 - val_acc: 0.9896\n",
      "Epoch 196/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1557 - acc: 0.9508 - val_loss: 0.0255 - val_acc: 0.9909\n",
      "Epoch 197/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1383 - acc: 0.9555 - val_loss: 0.0221 - val_acc: 0.9918\n",
      "Epoch 198/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1514 - acc: 0.9518 - val_loss: 0.0243 - val_acc: 0.9922\n",
      "Epoch 199/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1453 - acc: 0.9562 - val_loss: 0.0233 - val_acc: 0.9926\n",
      "Epoch 200/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1444 - acc: 0.9561 - val_loss: 0.0212 - val_acc: 0.9926\n",
      "Epoch 201/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1523 - acc: 0.9540 - val_loss: 0.0230 - val_acc: 0.9918\n",
      "Epoch 202/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1418 - acc: 0.9544 - val_loss: 0.0229 - val_acc: 0.9922\n",
      "Epoch 203/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1428 - acc: 0.9541 - val_loss: 0.0236 - val_acc: 0.9909\n",
      "Epoch 204/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1497 - acc: 0.9533 - val_loss: 0.0226 - val_acc: 0.9926\n",
      "Epoch 205/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1392 - acc: 0.9590 - val_loss: 0.0276 - val_acc: 0.9905\n",
      "Epoch 206/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1444 - acc: 0.9549 - val_loss: 0.0232 - val_acc: 0.9931\n",
      "Epoch 207/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1294 - acc: 0.9589 - val_loss: 0.0247 - val_acc: 0.9918\n",
      "Epoch 208/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1410 - acc: 0.9563 - val_loss: 0.0263 - val_acc: 0.9913\n",
      "Epoch 209/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1401 - acc: 0.9562 - val_loss: 0.0239 - val_acc: 0.9926\n",
      "Epoch 210/500\n",
      "9216/9216 [==============================] - 66s - loss: 0.1498 - acc: 0.9545 - val_loss: 0.0224 - val_acc: 0.9926\n",
      "Epoch 211/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1414 - acc: 0.9549 - val_loss: 0.0237 - val_acc: 0.9926\n",
      "Epoch 212/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1571 - acc: 0.9528 - val_loss: 0.0257 - val_acc: 0.9896\n",
      "Epoch 213/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1500 - acc: 0.9539 - val_loss: 0.0244 - val_acc: 0.9918\n",
      "Epoch 214/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1425 - acc: 0.9559 - val_loss: 0.0248 - val_acc: 0.9926\n",
      "Epoch 215/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1353 - acc: 0.9561 - val_loss: 0.0216 - val_acc: 0.9926\n",
      "Epoch 216/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1480 - acc: 0.9537 - val_loss: 0.0261 - val_acc: 0.9922\n",
      "Epoch 217/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1426 - acc: 0.9572 - val_loss: 0.0271 - val_acc: 0.9918\n",
      "Epoch 218/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1447 - acc: 0.9540 - val_loss: 0.0253 - val_acc: 0.9926\n",
      "Epoch 219/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1415 - acc: 0.9551 - val_loss: 0.0258 - val_acc: 0.9926\n",
      "Epoch 220/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1450 - acc: 0.9554 - val_loss: 0.0256 - val_acc: 0.9926\n",
      "Epoch 221/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1431 - acc: 0.9531 - val_loss: 0.0242 - val_acc: 0.9909\n",
      "Epoch 222/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1412 - acc: 0.9550 - val_loss: 0.0198 - val_acc: 0.9918\n",
      "Epoch 223/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1420 - acc: 0.9541 - val_loss: 0.0251 - val_acc: 0.9905\n",
      "Epoch 224/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1318 - acc: 0.9569 - val_loss: 0.0241 - val_acc: 0.9931\n",
      "Epoch 225/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1478 - acc: 0.9539 - val_loss: 0.0274 - val_acc: 0.9926\n",
      "Epoch 226/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1362 - acc: 0.9580 - val_loss: 0.0265 - val_acc: 0.9913\n",
      "Epoch 227/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1360 - acc: 0.9567 - val_loss: 0.0269 - val_acc: 0.9896\n",
      "Epoch 228/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1368 - acc: 0.9570 - val_loss: 0.0239 - val_acc: 0.9922\n",
      "Epoch 229/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1366 - acc: 0.9565 - val_loss: 0.0228 - val_acc: 0.9909\n",
      "Epoch 230/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1315 - acc: 0.9606 - val_loss: 0.0227 - val_acc: 0.9926\n",
      "Epoch 231/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1376 - acc: 0.9571 - val_loss: 0.0263 - val_acc: 0.9922\n",
      "Epoch 232/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1376 - acc: 0.9581 - val_loss: 0.0261 - val_acc: 0.9913\n",
      "Epoch 233/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1395 - acc: 0.9580 - val_loss: 0.0234 - val_acc: 0.9909\n",
      "Epoch 234/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1436 - acc: 0.9545 - val_loss: 0.0258 - val_acc: 0.9909\n",
      "Epoch 235/500\n",
      "9216/9216 [==============================] - 67s - loss: 0.1374 - acc: 0.9579 - val_loss: 0.0256 - val_acc: 0.9913\n",
      "Epoch 236/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1368 - acc: 0.9577 - val_loss: 0.0279 - val_acc: 0.9909\n",
      "Epoch 237/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1473 - acc: 0.9558 - val_loss: 0.0226 - val_acc: 0.9931\n",
      "Epoch 238/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1283 - acc: 0.9593 - val_loss: 0.0248 - val_acc: 0.9922\n",
      "Epoch 239/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1524 - acc: 0.9535 - val_loss: 0.0296 - val_acc: 0.9926\n",
      "Epoch 240/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1523 - acc: 0.9537 - val_loss: 0.0227 - val_acc: 0.9935\n",
      "Epoch 241/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1569 - acc: 0.9511 - val_loss: 0.0261 - val_acc: 0.9926\n",
      "Epoch 242/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1521 - acc: 0.9544 - val_loss: 0.0249 - val_acc: 0.9918\n",
      "Epoch 243/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1351 - acc: 0.9566 - val_loss: 0.0256 - val_acc: 0.9931\n",
      "Epoch 244/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1393 - acc: 0.9564 - val_loss: 0.0225 - val_acc: 0.9926\n",
      "Epoch 245/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1304 - acc: 0.9593 - val_loss: 0.0237 - val_acc: 0.9931\n",
      "Epoch 246/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1394 - acc: 0.9550 - val_loss: 0.0238 - val_acc: 0.9926\n",
      "Epoch 247/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1403 - acc: 0.9548 - val_loss: 0.0225 - val_acc: 0.9931\n",
      "Epoch 248/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1388 - acc: 0.9562 - val_loss: 0.0251 - val_acc: 0.9922\n",
      "Epoch 249/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1429 - acc: 0.9539 - val_loss: 0.0256 - val_acc: 0.9944\n",
      "Epoch 250/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1434 - acc: 0.9582 - val_loss: 0.0228 - val_acc: 0.9935\n",
      "Epoch 251/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1341 - acc: 0.9609 - val_loss: 0.0229 - val_acc: 0.9926\n",
      "Epoch 252/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1383 - acc: 0.9589 - val_loss: 0.0230 - val_acc: 0.9935\n",
      "Epoch 253/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1365 - acc: 0.9568 - val_loss: 0.0258 - val_acc: 0.9926\n",
      "Epoch 254/500\n",
      "9216/9216 [==============================] - 68s - loss: 0.1470 - acc: 0.9569 - val_loss: 0.0216 - val_acc: 0.9931\n",
      "Epoch 255/500\n",
      "9216/9216 [==============================] - 80s - loss: 0.1396 - acc: 0.9575 - val_loss: 0.0264 - val_acc: 0.9926\n",
      "Epoch 256/500\n",
      "9216/9216 [==============================] - 84s - loss: 0.1341 - acc: 0.9567 - val_loss: 0.0224 - val_acc: 0.9935\n",
      "Epoch 257/500\n",
      "9216/9216 [==============================] - 84s - loss: 0.1350 - acc: 0.9570 - val_loss: 0.0218 - val_acc: 0.9935\n",
      "Epoch 258/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1451 - acc: 0.9564 - val_loss: 0.0245 - val_acc: 0.9931\n",
      "Epoch 259/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1405 - acc: 0.9570 - val_loss: 0.0294 - val_acc: 0.9913\n",
      "Epoch 260/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1478 - acc: 0.9550 - val_loss: 0.0243 - val_acc: 0.9931\n",
      "Epoch 261/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1474 - acc: 0.9531 - val_loss: 0.0242 - val_acc: 0.9926\n",
      "Epoch 262/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1471 - acc: 0.9586 - val_loss: 0.0220 - val_acc: 0.9926\n",
      "Epoch 263/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1454 - acc: 0.9558 - val_loss: 0.0233 - val_acc: 0.9948\n",
      "Epoch 264/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1405 - acc: 0.9583 - val_loss: 0.0238 - val_acc: 0.9931\n",
      "Epoch 265/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1373 - acc: 0.9571 - val_loss: 0.0261 - val_acc: 0.9926\n",
      "Epoch 266/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1391 - acc: 0.9537 - val_loss: 0.0264 - val_acc: 0.9909\n",
      "Epoch 267/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1418 - acc: 0.9576 - val_loss: 0.0226 - val_acc: 0.9931\n",
      "Epoch 268/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1428 - acc: 0.9543 - val_loss: 0.0251 - val_acc: 0.9922\n",
      "Epoch 269/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1450 - acc: 0.9559 - val_loss: 0.0233 - val_acc: 0.9926\n",
      "Epoch 270/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1453 - acc: 0.9565 - val_loss: 0.0270 - val_acc: 0.9918\n",
      "Epoch 271/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1388 - acc: 0.9557 - val_loss: 0.0265 - val_acc: 0.9926\n",
      "Epoch 272/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1468 - acc: 0.9588 - val_loss: 0.0250 - val_acc: 0.9913\n",
      "Epoch 273/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1368 - acc: 0.9603 - val_loss: 0.0230 - val_acc: 0.9935\n",
      "Epoch 274/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1400 - acc: 0.9577 - val_loss: 0.0235 - val_acc: 0.9926\n",
      "Epoch 275/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1375 - acc: 0.9582 - val_loss: 0.0253 - val_acc: 0.9918\n",
      "Epoch 276/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1422 - acc: 0.9566 - val_loss: 0.0261 - val_acc: 0.9931\n",
      "Epoch 277/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1370 - acc: 0.9590 - val_loss: 0.0229 - val_acc: 0.9918\n",
      "Epoch 278/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1376 - acc: 0.9553 - val_loss: 0.0254 - val_acc: 0.9926\n",
      "Epoch 279/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1401 - acc: 0.9559 - val_loss: 0.0259 - val_acc: 0.9948\n",
      "Epoch 280/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1403 - acc: 0.9576 - val_loss: 0.0242 - val_acc: 0.9931\n",
      "Epoch 281/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1299 - acc: 0.9588 - val_loss: 0.0262 - val_acc: 0.9922\n",
      "Epoch 282/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1322 - acc: 0.9593 - val_loss: 0.0249 - val_acc: 0.9913\n",
      "Epoch 283/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1361 - acc: 0.9563 - val_loss: 0.0225 - val_acc: 0.9931\n",
      "Epoch 284/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1356 - acc: 0.9572 - val_loss: 0.0266 - val_acc: 0.9909\n",
      "Epoch 285/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1387 - acc: 0.9542 - val_loss: 0.0229 - val_acc: 0.9931\n",
      "Epoch 286/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1400 - acc: 0.9572 - val_loss: 0.0235 - val_acc: 0.9926\n",
      "Epoch 287/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1411 - acc: 0.9550 - val_loss: 0.0342 - val_acc: 0.9900\n",
      "Epoch 288/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1331 - acc: 0.9588 - val_loss: 0.0207 - val_acc: 0.9931\n",
      "Epoch 289/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1482 - acc: 0.9532 - val_loss: 0.0275 - val_acc: 0.9922\n",
      "Epoch 290/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1462 - acc: 0.9564 - val_loss: 0.0224 - val_acc: 0.9931\n",
      "Epoch 291/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1263 - acc: 0.9582 - val_loss: 0.0212 - val_acc: 0.9922\n",
      "Epoch 292/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1488 - acc: 0.9542 - val_loss: 0.0246 - val_acc: 0.9922\n",
      "Epoch 293/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1372 - acc: 0.9553 - val_loss: 0.0258 - val_acc: 0.9918\n",
      "Epoch 294/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1409 - acc: 0.9569 - val_loss: 0.0265 - val_acc: 0.9905\n",
      "Epoch 295/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1326 - acc: 0.9592 - val_loss: 0.0256 - val_acc: 0.9913\n",
      "Epoch 296/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1506 - acc: 0.9550 - val_loss: 0.0202 - val_acc: 0.9935\n",
      "Epoch 297/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1354 - acc: 0.9593 - val_loss: 0.0233 - val_acc: 0.9918\n",
      "Epoch 298/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1393 - acc: 0.9557 - val_loss: 0.0216 - val_acc: 0.9931\n",
      "Epoch 299/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1432 - acc: 0.9569 - val_loss: 0.0225 - val_acc: 0.9931\n",
      "Epoch 300/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1452 - acc: 0.9555 - val_loss: 0.0238 - val_acc: 0.9931\n",
      "Epoch 301/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1427 - acc: 0.9550 - val_loss: 0.0218 - val_acc: 0.9935\n",
      "Epoch 302/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1455 - acc: 0.9563 - val_loss: 0.0215 - val_acc: 0.9931\n",
      "Epoch 303/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1463 - acc: 0.9548 - val_loss: 0.0237 - val_acc: 0.9935\n",
      "Epoch 304/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1410 - acc: 0.9552 - val_loss: 0.0244 - val_acc: 0.9922\n",
      "Epoch 305/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1516 - acc: 0.9561 - val_loss: 0.0241 - val_acc: 0.9931\n",
      "Epoch 306/500\n",
      "9216/9216 [==============================] - 71s - loss: 0.1389 - acc: 0.9556 - val_loss: 0.0227 - val_acc: 0.9918\n",
      "Epoch 307/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1409 - acc: 0.9581 - val_loss: 0.0271 - val_acc: 0.9926\n",
      "Epoch 308/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1313 - acc: 0.9596 - val_loss: 0.0220 - val_acc: 0.9935\n",
      "Epoch 309/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1307 - acc: 0.9594 - val_loss: 0.0238 - val_acc: 0.9922\n",
      "Epoch 310/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1358 - acc: 0.9575 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "Epoch 311/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1496 - acc: 0.9533 - val_loss: 0.0216 - val_acc: 0.9918\n",
      "Epoch 312/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1386 - acc: 0.9600 - val_loss: 0.0244 - val_acc: 0.9931\n",
      "Epoch 313/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1383 - acc: 0.9558 - val_loss: 0.0212 - val_acc: 0.9913\n",
      "Epoch 314/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1439 - acc: 0.9541 - val_loss: 0.0249 - val_acc: 0.9922\n",
      "Epoch 315/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1396 - acc: 0.9564 - val_loss: 0.0221 - val_acc: 0.9935\n",
      "Epoch 316/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1330 - acc: 0.9570 - val_loss: 0.0283 - val_acc: 0.9905\n",
      "Epoch 317/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1389 - acc: 0.9583 - val_loss: 0.0220 - val_acc: 0.9939\n",
      "Epoch 318/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1301 - acc: 0.9615 - val_loss: 0.0263 - val_acc: 0.9931\n",
      "Epoch 319/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1449 - acc: 0.9578 - val_loss: 0.0234 - val_acc: 0.9939\n",
      "Epoch 320/500\n",
      "9216/9216 [==============================] - 71s - loss: 0.1305 - acc: 0.9582 - val_loss: 0.0219 - val_acc: 0.9948\n",
      "Epoch 321/500\n",
      "9216/9216 [==============================] - 71s - loss: 0.1400 - acc: 0.9563 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "Epoch 322/500\n",
      "9216/9216 [==============================] - 69s - loss: 0.1420 - acc: 0.9582 - val_loss: 0.0212 - val_acc: 0.9935\n",
      "Epoch 323/500\n",
      "9216/9216 [==============================] - 70s - loss: 0.1442 - acc: 0.9556 - val_loss: 0.0239 - val_acc: 0.9931\n"
     ]
    }
   ],
   "source": [
    "# トレーニング\n",
    "hist = model.fit_generator(\n",
    "    datagen.flow(X_train, Y_train, batch_size=16),\n",
    "    samples_per_epoch=X_train.shape[0],\n",
    "    nb_epoch=500,\n",
    "    callbacks=[checkpoint_collback, early_stop],\n",
    "    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g2.2xlarge (1 Epoch 8s程度)\n",
    "\n",
    "```\n",
    "Epoch 1/500\n",
    "9216/9216 [==============================] - 8s - loss: 4.2577 - acc: 0.0205 - val_loss: 4.1268 - val_acc: 0.1102\n",
    "Epoch 2/500\n",
    "9216/9216 [==============================] - 8s - loss: 3.9113 - acc: 0.0748 - val_loss: 3.2396 - val_acc: 0.3242\n",
    "Epoch 3/500\n",
    "9216/9216 [==============================] - 8s - loss: 3.3561 - acc: 0.1603 - val_loss: 2.2879 - val_acc: 0.5182\n",
    "Epoch 4/500\n",
    "9216/9216 [==============================] - 8s - loss: 2.8414 - acc: 0.2580 - val_loss: 1.6689 - val_acc: 0.6558\n",
    "Epoch 5/500\n",
    "9216/9216 [==============================] - 8s - loss: 2.4566 - acc: 0.3279 - val_loss: 1.3113 - val_acc: 0.7140\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xl8VNXB//HPyWTfIQmEAGETWQTZXFBAxKVUcUERKeoj\nLnWp2yO2Un/2abVWbR+tG7WorW0BFRQFqjzWFcEFQRQUBQIIEvZAEsi+z5zfH4cEiCxJSDIzyff9\nevFK5s6995y5E+Z+55xzzzXWWkRERESOJcTfFRAREZHgoNAgIiIidaLQICIiInWi0CAiIiJ1otAg\nIiIidaLQICIiInWi0CAiIiJ1otAgIiIidaLQICIiInWi0CAiIiJ1Uu/QYIwZYYx5yxizwxjjM8Zc\nUodtzjbGrDDGlBljNhhjJjWsuiIiIuIvDWlpiAG+AW4DjnnjCmNMV+D/gIXAAOAZ4EVjzPkNKFtE\nRET8xBzPDauMMT5grLX2raOs87/ABdbakw9aNhtIsNZe2ODCRUREpFk1x5iGocCHtZa9B5zRDGWL\niIhIIwlthjJSgd21lu0G4o0xEdba8tobGGOSgNFAJlDW5DUUERFpOSKBrsB71trcxtxxc4SGhhgN\nvOLvSoiIiASxq4FZjbnD5ggNWUD7WsvaAwWHa2XYLxPg5Zdfpk+fPk1YtcA3efJknnrqKX9XIyA0\nx7Gw1uK1XkJDAjVP1/04VHmrCPWEUlFVQX55PikxKUddv9JbSZgn7Ljrt3nfZrblb6NnUk/axbTD\nE+KhsLyQrKIserTtQYhpnF7RIx0Hn/Xh9Xkb5bUcTpW3igpfBdFh0Q3eh7WWMm8ZUaFRWGvJLs4m\nvzyfbondCPWE4vV5Ka4oJi4ijsLyQsJCwwgLCaO4opj4iHhW7lrJ+tz19ErqRa/kXtz7y3v51e9/\nRZfELpRUlBAeGk6lt5LMvEy8Pi/xkfF0iOtAVGgUpZWlhJgQIkIj2F20mzfWvkGHuA6c0/UcEiIT\nMMbg9Xmp9FUSGRp52Prnl+Wzr3Qf6YnphJgQqrxVWCxhnjBKK0uZt24epZWljOk5hg5xHWpec5Wv\nijBPGFXeKsq8ZcSExdSU5/V5CQ8Np6iiqGb54Y7btvxtdIjrgCfEw97SvVSPyyuqKOKR3zzC7//0\newrLC0mOSSY5OpniimJiwmMAKKksYVv+NroldiM8NLxmv+VV5YSGhOIJ8WCtZUfhDpKikgjzhLFs\n+zJSolMoqihibfZatuZvJT0hnfSEdFJiUkiJTqFtVFs8IZ4G/z00toyMDK655hrYfy5tTM3xybgU\nuKDWsp/sX34kZQB9+vRh8ODBTVWvoJCQkNDij4G1tuYDoqSyhNLKUpKik370fO1jsSF3A20i29Sc\nDKs/PPLK8vjP9/9hcIfBVPmq2FawjcjQSIanD8fr87I2ey3ZJdlUeivZkLuBFbtWsDV/K1eedCUz\nVs1gQ+4GLu9zOW0j2wLuw6ikqoSxvcaSXZLN97nfExUWxTndziHCE4HXegkxIXyc+THd23SnpLKE\n/2z8D16fF4Dk6GQGpg6kY1xHCsoLODHpRIalD2Pzvs28uf5N3lr/Fst3LCfEhDBl2BRuGnwT//n+\nPyzespihHYdy5UlXsjlvM79d9FtObncy28q38bMlP2NP8R56tO3BiPQRpMWl8fra1/lh3w+kxaWR\nGpvKwh8Wclmfy1ifs5412Ws4p9s5ZOZlUlRRRNfErgxoP4CYMPdhujp7NQt/WMiFPS+kR5serM1Z\ny57iPXh9XjondObEticSYkLwWR8b921kd9FukqKTyCnJYWfhTvLL8gkxIbSJasP2gu0171GICSHC\nE0FpVSkA3dt056SUk8gqyiIzL5MzOp/BlrwtFFYUMrTTUDbv20yPtj245MRLGJI2hE+2fMKy7cvY\nkLuBnYU72VW0i0pvJW2j2lJeUM7NX91Mv3b9KKks4cudXzK+73jmZcxjV9EuRnYZSYfYDizdvpTM\nvEwAQkNCuWXILQxIHcC/vvkXX+/6mrKqMmLCY0iLSyM5OpmNezeSXZwNgCfEw+geo+mS0IWc0hz6\nJvdl6vKp7CzcSUp0Chf2vJBrTr6GL7Z/wcLNCxmYOpD3Nr1HTkkOXRK6MCh1EF0TuxIbHktpVSk5\nJTnEhccxN2Muq3avonN8ZworCskrywMgwhNB//b92ZK3heyS7JpjDmAwWCwJEQnkl+cTGhJKVWaV\nO9A5cOWSK4/6/yw2PJZhnYexOHMx5d5yIkMjqfBWEBseS+HuQh7Z+AiJkYmM7T2WxZmL2Zq/lc7x\nnckry6NzQmfCPeFsL9jOKWmnsDhzMSWVJcSGx3JSykmszV6L13o5uf3JrNmzhtKqUiI8ETy34znS\nE9IZ0mEIm/ZtYm32Wq7oewWLMxeTVZRFWlwad512F39b+Te25m8lOTqZrKIsEiMTSYtLI9wTTlpc\nGiO7jCQmLIbX1rzGp1s/pX1MezwhHnYW7jz0Re6DSz4+MAtASnQK2SXZ9GzbkzBPGBnZGVgsseGx\n9G/Xn6ToJIoqivh82+e0i2nHmZ3P5KudX/HDvh/oktCFLold+GTLJzX7iw6L5oS2J/Durncp2VpS\ns/zrW75mYOrAox5/P2n07v16Xz1hjIkBTgAMsBK4B1gE7LXWbjPG/BFIs9ZO2r9+V+A7YBrwT+Bc\n4GngQmtt7QGS1WUMBlasWLGixZ8wj+WSSy7hrbeOeHGKX5RXlbMocxHtY9rTJ6UPuSW5zMuYR7gn\nHJ/1kVuaS35ZPm9kvEGvpF68dNlLZBVlMeXDKXSI7cCYnmP405I/cWLSifyw7we2F2xn+qXTeWLp\nE7y36T0ALux5IZf1voy5GXNZnLmYk1JO4odpP3DmlDNJik5iZ+FO3t/0PlGhUQxPH866nHXugzwm\nhZLKEgrKC35U76SoJBdK9p/AAKJCoxjcYTBxEXG8u/FdeiX14rLel/Hupnep9Fa6dcKiqPRWsmr3\nKkJDQunZtif7yvaRVZR1yP7jI+IpKC/AYDiry1nER8Rjsews3MnqPaup8FbUrNuvXT9W71lNuCec\nc7udy6iuo9hRuINnvngGcCeIk9q5D2Of9WEw9E7uTVZRFsUzirnpzzfRKb4T63PX8/6m98kuzubS\n3pcysP1ANuzdwLb8bYzsMpLnVzxPSnQKNw2+iTcy3qBfSj9SY1PZuG8j3+3+rqZO7WLacX7385m1\nehblVeX0b9+f1JhUPCEeftj3Q81JFyA9IZ2OcR3ZW7aX5Khk0uLSaBPVBq/Py57iPQxIHcDQTkNZ\ns2cNOwp3UF5VTmJkIu1j2/P6mtfZXbybNlFt6Bzfmc+2fkan+E4kRCTw1a6v6NGmB2uy1/Dt7m8P\nOQ4npZxEWlwaHWI7EBkayc7Cncy4bwYX/PYClu9cjsEwuMNgXl39KsPTh3Nut3P5bNtnZBVlMaD9\nAAamDsRg2FG4gyeXPkmlr5Lzu5/PyC4ja77N7yraxe7i3XRP7E7H+I4YDIUVhby25jUKywtJjEzk\n66yvGdt7LFf0uYI12WuYlzGP9bnrCQ0J5Zxu5/Dd7u8Y2XUkfZL7sGnfJr7J+obtBdspqSwhwhNB\ncnQy+8r2MSh1kAuD+zaTEJlAr6ReJEcn83XW16zctZLU2FQGpQ5iX9k+2ka1pcJbQWllKQmRCazL\nWcfA1IFc2PNC1uWsY+Wulfx18l/533/+b02QLqty54r+7fsT4YkgtzSXhT8s5KPMj7jwhAvpENeB\n/LJ8YsJjGN93PPvK9rF021JW7V7FnDVzGJg6kPO7n88P+36gTVQbMvMyqfBWkBqbyufbPmdY52Gc\n3fVsvs76mlW7V9E7qTfhnnBW7V7FSSkncfXJV9M2qi3vbXyPr3Z+xVe7viIxMpF+Kf145btXGJ4+\nnJ/0+AlvrX+L19a8xhmdzuCq/leRVZRF7+TeNaGpvKqczPxMPs78mCpfFad3Op1bh9zKil0rABiR\nPoJwj2sxSIhM4Dc//w3/89z/kBiZSEZOBpv2bqJbm24s276MEBPCKWmncELbE1iydQnrc9ezt3Qv\nYZ4whnUexrqcdazNXsug1EGM6DKCqV9MZX3uel6+7GViw2NJjEykd3JvPCEevD4v2SXZ7Czcyc7C\nnYzqOqqmNSMQrFy5kiFDhgAMsdaubMx9NyQ0jMSFhNobzrDW3mCM+RfQxVp7zkHbnAU8BfQFtgMP\nWWtfOkoZCg37NUVoKCgv4Nvd31JSWUKf5D50jO/Iv9f9mz3Feziz85n0b9efWd/N4vW1r5NTkkN8\nRDy5pbl0S+yGz/r4aPNH5JYeGFtjMISGhOK1XgyGtlFtCfeEc36P83l7w9tkl7hvbT3a9GBP8R4K\nKwoZkT6CksoSUmJSyCrK4pusb2gX047fn/17rLVMXzWd5TuWk56Qzs8H/ZzNeZt5/+H3GTh5IHtL\n9xIZGsmkAZPYtG8TK3etpH+7/nRO6MzOwp0YDDcOvpGM7AxiwmPo0aYH2SXZvLr6VZKikji769mk\nxqYSGhJKSkxKTVfEzsKdtI1qe8Qm2Y17N5ISnUJCZALWWtZmr8UT4iHEhFBSWUL/dv3ZU7wHiyUt\nLu2QbX3Wx77SfcSEx/Dq6ld5a/1bXNb7Mi7rcxmx4bE16y3OXMyWvC1c0PMC2sW0Y0fBDj7e8jHF\nFcVMGjgJg+HysZezYMGCmm2stZRVlREVFvWjOld4K/AYT0A1ndbFlrwtfJ31NWd2PpN2Me0Ou87h\n/m/4rO+Y3R8b926ktLKU/u3717te5VXlRIRG1Dy21vLFji9Ijk7mhLYn1Ht/jSUQv1zU1fe539Ot\nTbejdgmWV7me7IOP/eE05nGw1lLhrThmmYGoKUNDvbsnrLUfc5RLNa211x9m2SfAkPqWJWBxfXid\nEzrXLNtX6r7lntD2BEJDQpmbMZdnlz/Lye1P5qbBN7G7eDe/W/Q7soqyKKwoxOvz8psRv6FvSl9e\n+vYlXlvzWk2TZ3Vz6Fc7v8JgCPeE85MeP2HBhgUMTx9OtzbdKCgvoG9KX77P/Z4QE8LPB/+cq/pf\nRWF5IZv2bcJay9jeY4kJj8FgDjlBbS/Yztsb3iY1NpWfnvBTdhXtYsXOFVze5/KaLomC8gKmfjGV\nSQMm1bzOX5z6C3JLcokNj635T3vJPy7hravq/oHQNbFrze8d4zses/mw9om+toNPCsa4b8C1Vfff\n1hZiQmq6XK4beB3XDbzusOud3fXsQx53jO/IVf2vOmRZ7b5eY8xhAwNQ8y0s2HRJdE3D9VWX8RLH\nc3KvfQIxxjC009AG70+gZ1LPY67jjxO3MSYoA0NTC9zRXi1Y7W8rpZWlh3zoV3gr+PuKv7Nq9yq+\nSPyC9KfTeXXcq6TEpPCHT/7A4szFAPRO7k1SVBJLti1hePpwXvr2Jf6y/C8AnNHpDCb2m0hMeAxb\n8rZw7wf3YrF0iu/EU6OfYlTXUcSGx/K3FX/jrQ1v8d4173FWl7P4r/n/xbyMefzjkn9ww6Abjvla\nhqUPO+rzneI7ccspt9Q87prY9ZCTObhm/f85639+tO3B4xoAJk6ceMz6tAY6Do6OwwE6Fo6OQ9M7\nrhkhm0pL7p54f9P7jH11LK9d8RoX9ryQ+z68jz8v/TO9k3vXnEw35G5gS94WBqYO5OT2J5NXlsf/\nbfg/Kn2VnN7xdG4Zcgupsak8/vnj5JXl8fj5j3Nu93MpKC/gm6xvqPJVcXbXsw/51rW9YDs+66Nj\nXMejNlX7rI89xXtIjU1t6kMhIiJNIKDGNDSHlhAa8sryeGnVSyzKXERZVRl/GPUH+rfvz8nPncym\nfZuIC4+ja2JXVu1exa+H/Zqckhz2lu4FICY8hl+d8auaPteyqjJufOtGTk07lbtOv6vRLlkTEZGW\nJ6DGNMgBRRVFFJQX0CHW9WM//vnjfPDDB5zQ5gRe+e4VSqtKOavLWewp3sPwfw2nV1Ivvt/7PYsm\nLeLW/7uV+Ih4Pr3+U87sfOZRy4kMjeSVyzXXlYiI+JdCQx1VeCvYvG8zG/duZOn2pbz9/dusylqF\nxZIcnUxiZCIb927k7K5ns2DDAm4Zcgv3nHEPHeI6UFZVxoOLHySrKIv7ht/HWV3OYu3ta/39kkRE\nROpFoaEOyqvKOe3F02quHU+KSuKnJ/yUO069g6ToJL7d/S07C3fy9OinGXPimB9tHxkayZ/O+1Nz\nV1tE/MDnA2Pcv+ZQVgahoe6fNI01a6BDB2jb1t818T/9mdXBY0seY232WuZPmM+g1EGkJ6Qfctnb\n2N5j/Vg7EQGwFv75Txg1CmJiYN48+K//gtjYY2/bUFu3QnIyRO+fUXrXLrjgAndyefFF2LHDhYhB\ngyA+HjZtgqoq6NYNcnPhmWdg8mRoX3ui/f3KyuCJJ+C00+D88w99zueDZ5+F3/wGkpJgyhS44QaI\njASv1/0LP8oVt+Xl8O67rr5ZWe61nHaa28bnc9uH1ZqJ2+uFv/8dpk+HqCj47W/dcR840L32Dz+E\nX/wCIiLc8rVrYeFC2LAB+vWDm2+GkMMMyVqyxNV7yP4L89evd+9bx47usbXw3nuwcqV7nf/8JyQk\nwIQJx3yLahQWwssvwzvvuEA3YgTcdJN7X269FXr0gHvvPTTsVb9HjzwC6enw3HPutQ0b5p4rKoKe\nx75itEXRQMhjWLFzBcP+OYy7h96t1gIJeIf7lmut+3CLizv+/VdWum+01fsvLITdu6FNG3fiOpjX\nC7/+NZx+Oowff2D5pk3uBBUXBxs3upPuF1+4D/TnnoOcHHdi/dnP3PqrV0N2tvugfuABt23fvu4D\n3+t1H+KJiTBtGtx5J6SmutCwaZM76Zx+OvTqBZdccuAEHhUFmzfDCy/Anj3upHfCCe6kds01cP31\n8M03UFAAY8a4UPDdd+5Edf/97udJJ7kTdlQUtGsHFRXu+ISHu/rv2XPgNXfpAj/5iTvhglvf43En\n2vPOcyfE6pNpTo4LCosXu5N5ZqY7eU+b5r7tfvgh9Onj6vfcc+6El58Pr73mjmlMjCvbWneiKylx\n701UlNv3VVe54/Q//+NOvt27u3BTXu7ex6lTXVnbt8OTT8KKFe49MMZtv2wZXHwx/PCDWw6ufl6v\nO77Dh7t///d/7vmICFdGRoY7xrm5cO21bt0FC+Dcc+Ff/3J1nzsXHn/cHY927WDmTPc+/etfsHy5\nK6tfvwPl/uQn7u/hlFPgrLPccf/8czjjDOja1f19rVnjXvurr7r6n322+xtetMiFu+uvhz/+0e3v\ntttc3f7+d7ef9evd8ilT4O233d8AuJC3d68r7+c/d9vX/vv3J1094SfrctYxcvpIuiZ2ZdGkRcd1\ngxqR2r7/3n2YejzuA/6ll9y3yQ4HzQ/11FPuhDBlyoFvs7VlZMC//w3//d/uBFRU5D54zz/fnYju\nvNPte+VKePNN9y8iwn1LPdK3JJ/PbfPkk+4kdN117oN4zBh3wn7+eff8Y4+58jweuPBCePhh9+H/\n/ffuhPDss25/99/vTtZ/+pM7CdUWGupO7GvWuMceD3z9tTsuI0dCXh4MGOBe6xlnuBNI6YHZwImN\ndd/KJ02Cr75ydfrHP9xJZ8cOt/6+fW7ddu3cyeuLL1zY6NHD1cnrdXX89lv3e7WoKHcci4vd486d\nXVjKy4O773bBJC/PvYZ9+9z7EBnpTvr9+x84sXz7rXv9gwfDG2+4E9jFF7uTVOfO0KmTaxn53e/c\nif7SS937dNdd8Ic/uJYTgLQ0Fzasda/xhhsO/D3Nnu3eu/btXZ1/+MG9f9nZ7niFh7v3razM1ev3\nv4dVq1wAuugiePRR9/eRnOz+Npcvd7+ffro7Jnl57jWMHOkC0tdfu2/q77/v6tq7t3s91rr36b/+\ny4WCqCgXdl5+2QWT555zIeSii1x5N9zgWiQ2bnQn+wcegL/+1b2XISEuHNx5pyvzZz9zf0+Jie71\n9usHS5e6v52QkAOhorqlpXdv996dfro7uaenu+O1fbsrf9UqV+dTT4X77nPrpqbCFVe4MHnhhe7/\nZFmZCxGVle7vKj3dveZHHoFPPw2sFoemDA1YawPuHzAYsCtWrLDNbVv+NjvutXH2mnnX2OhHom2f\nZ/vY7OLsZq+HBJbi4sbbV26utdddZy1Ye/311vp81s6d6x736WPtM89YO2GCtXfc4ZaFhlrbo4e1\nmZkH6rJ0qdtu715ru3d363Xtam1YmLWnnuoed+5s7bXXut/j4qxNTna/jx1rbc+e1sbEWPvrX1t7\n6aXWnniitQ8/bO3o0e7xmWe6dS+5xNoxY6wNCXGPTzzR7QtcWZMnW7tokbXPPWdtr14H1qv+9/TT\n1t5/v7WRke7x8OHuta5fb+2XX7r6Z2S411Zebu2DD1o7f747Dt27W5uQYO2gQa6eMTHWvv22Owa7\nd1s7c6a1b71l7euvW/vYY67+5eXWVlRYW1Z26DEvLbV2+XL37xe/sHb8eGv/9rcD7+vate5xZaW1\nq1a5cnJzrd23z9o//MHahx6y9quvrH3zTWsLCqzdts397vPV7T0vKzvw/tU2Z461U6ZYe8op7hid\nd561WVmHruPzWbt1q7WbNrnfv/3W2g8/rFvZte3b547Xk0/++Dmv19oZM6zduNEdxy+/dMe0sX3/\nvSvDWmtLStzPjAz3t5KX5x4XFbm/rX37Dt32SPUpL7e2sND9nptr7fbt7v08mtxc997u3ese5+db\n+5//uLLrqrS07us2lxUrVljcrR4G28Y+Pzf2DhulUn4KDbsKd9mT/nqS7fDnDnbQ84PsrQtutYXl\nhc1aB2l8Xq87yTRku/Xrrb3mGvc/JT3dfaBa6z5Mr7jC2kcesXbzZvcBWFlp7cSJ1vbrZ+3jj7t1\n333X2ttvP7Dt889b2769OxnefLPb73//t7XdurkTdXKytcZY27+/e+5Xv3IfsN27u3+zZrmTaPUJ\nvHNna9u0ceUZY+2f/+xOKp995k6OSUnWXnmltcuWWRsba+0TT7j6Fxa6fcfGurIvu8zt84wzrB02\nzJXxyScHjkVGhjuhZ2dbu2aNtS++aO2ePYcer/Jyd+KdNcsdj4yMA8+VlFi7enXdT7Kffurq9ctf\nujKtPfYJINhVVVm7ZIn7KXI8mjI0tPruCWstczPm1txEKD4ins9u+Izeyb2btFxpOuvXw403wrp1\nrkm/rMw1z155JWzb5vq6R492fcX9+sHVV0NKimumLClxTddt2rim+MxM1wx6//2uCfu11w40f/bo\n4fpTK93NMOnSxTWFn38+fPCBa/4F11x/+umueTYkBMaNg6efds3MDz/smvjLylzzdVSU298JJ7jm\n66Qk14y7ZQuMHev6sTt1ck3EH37o+tavucb16ebm/rhftfq/tzGuPrVH2FdUuK4Aj8c1X0cd/hYW\nIhJENKahCc3PmM/lcy7n1LRT+Vm/nzFpwKQf3fNA/GPDBjcQrVs39zMvz50wk5NdMPjrX10/fXXf\n6ODBro/xxhvdSfDaaw/0e7dr5/pru3Rxfa2LF7uT/pIlbiBfbR6P67t//HF3wk9MdCfgZ55x/bwX\nXeRCyPbtrp89P9+Nlr/lFjfoz1p3Qt6xww22SkyEL7909e9Q655W5eUuIFSPFD+abdtcoGnKKwJE\nJLgpNDSRsqoy+v61L31S+vD2VW83WTlyKK/XfRM/+2w3YKzal1+6k2xqqhtY9dBDhw5IqxYf70JE\n+/auxaCgwI22rg4I7du7gVHduh27LhUV7rKwnBw4+WR3Qv7kE/ctfsoU91hEJJhoGukm8vAnD7Ot\nYBvvXP2Ov6vSIhUXu6b3d991I6JTU13z+cKF7sQ8fDi8/ro7MU+bBr/6lRv5Da4Z/9e/dpfJ7djh\nvqnHx7sWhu3b3Yjon/70QOjwel1XQVmZ+zZf18sLw8PdCOmDnXuu+yciIodqtaFhydYl/PGzP/Lg\nyAfpldzL39UJSIWF7mf1CTgjwzXbn3iie7xsmesDHzDAPV6/3p2Eu3aFV15xJ/2cHNcXv2ePuyQq\nN9f1w0+b5iaG6dDB7aO0FH75S3cJW26u20dCwo/rdOqph6+rx1O3lgUREWm4VhkatuZvZcIbExja\naSj/b8T/83d1AtKOHQeuj58yxQ0QfPRRN37g/vvdNcq33OKuAf/iC9cvP3y4aykYOdJNhDJ+PPzv\n/x75ZD5unGuFyMpys9L1dzf1pFOn5nudIiJSd60qNPisjzfXvcl9C+8jzBPGG+PfIDSkVR2CQ8yd\n65r677zTdQdkZrqTf1iYm9CkosJ1Adx334FJgsLC3GQmlZVu8pl162DoUNc90L27+/fuu27SleoZ\n/Y6kXTs3WFFERIJDqzpjPrn0Se794F7O6HQG08dOp0Nch2Nv1AIcfKndpk1ulP/kyW6Wurw8Nztd\nv35uStmKCtd6kJrqxh707AkzZrhtPR7388EHXVg4+WQXOp5/3j13551uEGJp6ZFnLxQRkeDVaq6e\n8Pq8dJ/anXO6ncO/Lv1Xo+wzGMyd68LBokVu8ODQoW4+gvR01y3w97+7sLB5s5uTvndvd+XBI48E\n1lzqIiJSN7p6ohG8s/EdtuZv5fZTb/d3VZpNRYUbj5CX5yYwSk93LQRTprirGm691XUP1O4imDTJ\nP/UVEZHA1ipCg7WWJ5c+ySlpp3BK2in+rk6jqu56qJ7N74MP3FiCtDQ3AVBmppvFcNIkdznia6+5\nsQgjR7qBiyIiInV1mDubtzxz1sxhUeYiHhz5oL+rctz27nW3tN282U1zHBHhpkCOjnZ3ivvFL9xg\nxJEj3SWLDzzgZi7cssVdEnnppW4/F17o5j0QERGpqxbf0rCjYAd3v3c3l/e5nDEnjvF3dY7b3/7m\nxhs8+qgLDI8+6loQjHG3ufV43OWOvWpNPdGunX/qKyIiLUeLDg1ZRVmMmjGKcE84f7ngL/6uTqN4\n5RXXStCtG1x+OZxzzoHnTj0Viop+HBhEREQaQ4sODY988gh7S/ey/KblpMWl+bs6x+TzufkPIiLc\n43vvdTdISkhwUy3/5Cfu7op//KO7YVJtF1zQvPUVEZHWpcWGhqKKImasmsGdp91J9zbd/V2dYyov\nh8suc3dpJjCCAAAgAElEQVRdvOUW11rw5z/D7be7QY2bNrmpl5OS3E2aREREmluLDQ2zvptFUUUR\nNw+52d9VOabiYnfFw6JF7vLHv//dXSZ53nnwl7+48Qrg5luoqHCzMoqIiDS3FhkatuVv46GPH+Li\nXhfTJbGLv6tzWLNmwccfQ36+63LYsgX+/W/XijB1qgsQp556IDAAnHGG/+orIiLS4i65rPBWcMEr\nFxAaEspzY57zd3V+pKLCXQZ59dXuRk979rjuhyVLDnQ7RES4ez5oRkYREQkkLa6l4ZMtn7Amew3L\nblwWcIMf//IXNxtjWZm7VPL/6QabIiISRFpcaFiwfgGd4ztzWsfT/F2VQ3zzDfzyl66F4a67YNAg\nf9dIRESkflpUaLDWsmDDAi468SLMwYMB/KioCB5+2N0psk8fd0fI6ksqRUREgkmLCg0ZORlsztvM\nRSceZhIDPygsdFM9r1wJ11wDv/61AoOIiASvFhUaPtr8EeGecEZ1HeXvqmCtu3xy1Sp3Eyld+SAi\nIsGuRV09sTZ7LScmnUhUWJTf6rB8ubuB1AUXuEsop09XYBARkZahRYWGjJwM+iT38Vv5lZVuAqa4\nOHc55S23uFkeRUREWoIW1T2xLmcdZw0+q9nL9Xrhuedg5kxYuxa+/BL69YPQFnV0RUSktWsxLQ15\nZXlkFWXRJ6X5WhoWLIBhw9zlk3fdBR07wvz57nFY2KGzOYqIiAS7FvNdOCM7A4Deyb2brcxnnoGd\nO2HgQNfSMGxYsxUtIiLS7FpOaMjJwGDoldSrWcrLzYXFi+Gvf3VjF0RERFq6oA8N1lpmfTeLdze+\nS9fErs125cRbb4HPB5de2izFiYiI+F3Qh4bv937PNfOvAWBMzzFNXp7PBy++6Lomhg2D1NQmL1JE\nRCQgBH1o+GTLJ4SYEOZcMYeT2p3U5OXNm+e6I049FR56qMmLExERCRgtIjQMTB3IuL7jmqW8Z56B\ns86Cjz9uluJEREQCRtCHhk+3fsrYXmObvJzNm+Hdd+Gzz2Du3CYvTkREJOAEdWjYlr+NzLxMzurS\ntBM6ff01jBzpbkB1yilwySVNWpyIiEhACurJnT7b+hkAw9OHN1kZOTlw4YXQqxfs3u3uLaGZHkVE\npDUK6tPflzu/pEebHqTEpDRZGU8+6VoYFiyAdu2arBgREZGAF9QtDV/t/IohaUOabP9798Jf/gJ3\n3KFLK0VERII2NHh9XlbuWskpHU5psjIefNDNy3DPPU1WhIiISNBoUGgwxtxujNlsjCk1xiwzxpx6\njPWvNcasMsYUG2N2GmP+YYxp27AqOxtyN1BcWdxkLQ0ffuhaGR59VN0SIiIi0IDQYIyZADwBPAAM\nAlYB7xljko+w/kjgn8DfgL7AFcBp+x832Fc7vwJgcIfBx7Obwyovh5tugnPOgTvvbPTdi4iIBKWG\ntDRMBl6w1s601q4DbgVKgBuOsP4pwGZr7V+ttVustZ8DL+CCQ4N9tfMrerbtSWJk4vHs5rBeeAG2\nboVnn4WQoO3AERERaVz1OiUaY8KAIcDC6mXWWgt8CJxxhM0+BFKNMRfs30d7YDzwdkMqXG1N9hpO\nbn/y8ezisPbsgYcfhuuugz59Gn33IiIiQau+36OTAQ+wu9by3cBhry+w1q4CrgVeN8ZUALuAfcAd\n9Sz7EDsLd9IpvtPx7OJH8vJg9GjweHRfCRERkdqafJ4GY8xQYDrwO+B9oAPwZ1wXxc+Ptu3kyZNJ\nSEg4ZNnEiROZOHEiu4p20SG2Q6PV0+eDq6+GLVvcfSU6dmy0XYuIiDSJ2bNnM3v27EOW5efnN1l5\n9Q0NOYAXaF9reXsg6wjb3A28Z619cv/j1caY24BPjTG/sdbWbrWo8dRTTzF48I8HOpZVlZFXlkdq\nbONNnvD44/Cf/7h//fs32m5FRESaTPUX6YOtXLmSIUOa5srCenVPWGsrgRXAudXLjDFm/+PPj1JG\nVa1lPsACpj7lV8sqcvmkQ1zjtDRs2+bmZLj3XrjggkbZpYiISIvTkGsDngRu2j/3Qm/geSAa1wWB\nMeaPxpgZB63/b2CcMeZWY0w3Y8ww4BngC2vtkVonjmpX4S6ARuue+N3vIC4OfvvbRtmdiIhIi1Tv\nMQ3W2jn752R4CNct8Q0w2lqbvX+VVKDzQevPMsbEA7fjxjLk4a6+uK+hld5VtD80NEJLw/btMGMG\nTJ3qgoOIiIgcXoMGQlprpwHTjvDc9YdZ9jyuRaJR7CrcRWhIKG2jjmtSScANerQWfvazRqiYiIhI\nCxaUUxdlFWWRGptKiDn+6n/6qZuPIfmw81mKiIhItaAMDY15ueWnn8KIEY2yKxERkRYteENDI4xn\nyM2FtWsVGkREROoiOEND4S5SY45/jobPPnM/FRpERESOLShDQ1ZRVqO0NPz97248Q5cujVApERGR\nFq7Jp5FubF6fl93Fu497TMPSpfD221Br9k0RERE5gqBraViXsw6f9dEzqedx7efBB6FfP7jyysap\nl4iISEsXdC0NS7YtwWM8nNbxtAbv47vv4P334ZVXICToYpOIiIh/BN0pc8m2JQxIHUBseGyD9/HU\nU9CpE4wf34gVExERaeGCLjR8vu1zhnUe1uDt9+51LQx33AFhYY1YMRERkRYuqELD7qLdbNy78bhC\nw6JFUFEBte4kKiIiIscQVKFh2fZlAJzZ+cwG72PhQujZE9LTG6tWIiIirUNQhYbMvEyiQqPoFN+p\nwftYuBDOPbcRKyUiItJKBFVo2FO8h3Yx7TDGNGj77dthwwaFBhERkYYIytDQUG+/DcbAqFGNWCkR\nEZFWIrhCQ0nDQ0NxMTz8MFx2GSQlNXLFREREWoHgCg3H0dLwxBOwZw88/ngjV0pERKSVaDWhYeZM\nuP566N69kSslIiLSSrSK0JCVBZs2wTnnNEGlREREWomgCQ0llSUUVRQ1KDQsWeJ+Dmv4nFAiIiKt\nXtCEhuzibIAGh4YuXaBjx8aulYiISOsRNKFhT/EeoOGhQa0MIiIix6fFh4b8fFi5UqFBRETkeAVd\naEiOTq7Xdn/6k7ub5dixTVErERGR1iOoQkObyDaEe8LrvM3WrfDUU/CrX0FaWhNWTkREpBUIqtBQ\n366JV1+F0FC4994mqpSIiEgrEjyhoQFTSK9eDf37Q1xcE1VKRESkFQma0JBTklPv8Qxr1sBJJzVR\nhURERFqZoAkN+WX5JEQm1Hl9rxcyMqBfvyaslIiISCsSPKGhPJ+EiLqHhs2bobRULQ0iIiKNJXhC\nQ1n9QsOaNe6nQoOIiEjjCJ7QUF6/7onVq6FNG+jQoQkrJSIi0ooERWjw+rwUVRTVu6XhpJPAmCas\nmIiISCsSFKGhoLwAoF4tDbpyQkREpHEFRWjIL88HID4ivk7rV1XBunW6ckJERKQxBUVoqGlpqGP3\nxMaNUFGhlgYREZHGFBShIb/MtTTUtXti9Wr3Uy0NIiIijSc4QsP+7om6tjSsWQMpKe6fiIiINI7g\nCA31bGnQIEgREZHGFxyhoTyf0JBQokKj6rT+6tXqmhAREWlswREa9s8Gaeow6UJ5OXz/vVoaRERE\nGltwhIZ6zAb55ZfukstTTmniSomIiLQyQREaCsoL6jxHw6JFkJAAgwY1caVERERamaAIDfW5w+Wi\nRTByJHg8TVwpERGRViY4QkNZ3bonysrg889h1KhmqJSIiEgrExyhoY4tDUuXuoGQ55zTDJUSERFp\nZYIjNJTVLTR89RXExupySxERkaYQHKGhjldPbNwIPXtCSFC8KhERkeASFKfXurY0bNwIJ5zQDBUS\nERFphQI+NFhr63zJpUKDiIhI0wn40FBcWYzFHjM0lJXBtm0KDSIiIk2lQaHBGHO7MWazMabUGLPM\nGHPqMdYPN8Y8YozJNMaUGWN+MMZcV5eyiiuKAYgJjznqeps3g7UKDSIiIk0ltL4bGGMmAE8ANwPL\ngcnAe8aYE621OUfY7HUgBbge2AR0oI6Bpbhyf2gIO3po2LjR/VRoEBERaRr1Dg24kPCCtXYmgDHm\nVmAMcAPwWO2VjTE/BUYA3a21efsXb61rYSWVJcCxWxo2boSoKOjQoa57FhERkfqoV/eEMSYMGAIs\nrF5mrbXAh8AZR9jsYuAr4NfGmO3GmPXGmMeNMZF1KbOme6IOLQ0nnAB1uBGmiIiINEB9WxqSAQ+w\nu9by3UCvI2zTHdfSUAaM3b+P54C2wI3HKrC6eyI6LPqo623YoK4JERGRptSQ7on6CgF8wFXW2iIA\nY8w9wOvGmNusteVH2nDy5MmUecpgB9z2xW1EhEYwceJEJk6c+KN1V6+Gm25qqpcgIiISeGbPns3s\n2bMPWZafn99k5dU3NOQAXqB9reXtgawjbLML2FEdGPbLAAzQCTcw8rCeeuopNoRvYOLcibxx3xvE\nRcQddr09eyArC04+uY6vQkREpAU43BfplStXMmTIkCYpr15jGqy1lcAK4NzqZcYYs//x50fYbAmQ\nZow5uH+hF671Yfuxyqwe03C07onvvnM/+/c/1t5ERESkoRoyT8OTwE3GmGuNMb2B54FoYDqAMeaP\nxpgZB60/C8gF/mWM6WOMOQt3lcU/jtY1Ua2ksoTI0Eg8IZ4jrvPttxAZqTENIiIiTaneYxqstXOM\nMcnAQ7huiW+A0dba7P2rpAKdD1q/2BhzPvAX4EtcgHgN+G1dyiuuLD7mlRPffefubOk5cq4QERGR\n49SggZDW2mnAtCM8d/1hlm0ARjekrOKK4mPO0fDttxrPICIi0tSC4t4TRxvP4PXCmjUKDSIiIk0t\n8ENDxdG7J3btcjer6tmzGSslIiLSCgV+aKg8evfErl3uZ1paM1VIRESklQr40FBSWXLMlgaA1NRm\nqpCIiEgrFfChoS4tDSEh0K5dM1ZKRESkFQr80FCHMQ3t2ulySxERkaYW+KHhGPM07Nql22GLiIg0\nh8APDRVHv+RSoUFERKR5BH5oqMOYBoUGERGRphf4oaEOYxoUGkRERJpewIeGksqSI7Y0+Hywe7dC\ng4iISHMI6NBQ5a2i0ld5xJaGnByoqlJoEBERaQ4BHRpKq0oBjtjSkJXlfio0iIiINL3ADg2VLjQc\n6eqJ6tkgFRpERESaXmCHhuqWhiN0T2gKaRERkeYT2KGh8ujdE9u2QUoKREQ0Z61ERERap4AODWVV\nZcCRWxq2bYP09OaskYiISOsV0KHhWAMht26Fzp2bs0YiIiKtV3CEhqO0NCg0iIiINI+ADg3V3ROH\nu3rCWtfSoO4JERGR5hHQoaHSWwlAuCf8R8/l50NRkVoaREREmktghwZfJR7jwRPi+dFz27a5n2pp\nEBERaR6BHRq8lUSEHv56yq1b3U+1NIiIiDSPwA4NvsrDdk2Aa2nweDQbpIiISHMJ7NDgPXpo6NjR\nBQcRERFpekEbGjRHg4iISPMK7NBwlO6JnTtdS4OIiIg0j8AODUdpacjJcfedEBERkeYR2KHBV0mE\n5/BXT+TkQHJyM1dIRESkFQvo0FDlqzpsS4O1Cg0iIiLNLaBDw5HGNBQVQUWFQoOIiEhzCujQUOGt\nOGxoyMlxPxUaREREmk9Ah4YjDYRUaBAREWl+gR0ajtA9odAgIiLS/AI6NFT5qg5774nq0JCU1MwV\nEhERacUCOjQcqXsiNxdiYiAqyg+VEhERaaUCOzQcpXtCXRMiIiLNK7BDg7eS8BCFBhERkUAQ0KGh\nwnfkSy4VGkRERJpXQIeGI80IqdAgIiLS/AI6NFR6K4949YRCg4iISPMK7NCggZAiIiIBI7BDw2Eu\nudTNqkRERPwjsEPDYVoa8vPB69XETiIiIs0tsEPDYVoacnPdT4UGERGR5qXQICIiInUS0KHBZ31E\neA69ekKhQURExD8COjQAamkQEREJEEEZGqKidLMqERGR5haUoUGtDCIiIs1PoUFERETqpEGhwRhz\nuzFmszGm1BizzBhzah23G2aMqTTGrKxrWQoNIiIigaHeocEYMwF4AngAGASsAt4zxhx1jkZjTAIw\nA/iwPuXVvvdEbi60bVufPYiIiEhjaEhLw2TgBWvtTGvtOuBWoAS44RjbPQ+8AiyrT2G1Wxr27lVL\ng4iIiD/UKzQYY8KAIcDC6mXWWotrPTjjKNtdD3QDfl/fCqp7QkREJDCE1nP9ZMAD7K61fDfQ63Ab\nGGN6Ao8Cw621PmNMvQpUaBAREQkM9Q0N9WKMCcF1STxgrd1UvbjOO3gX7tx6JzFhMQD4fFBUNJGk\npImNXlcREZFgM3v2bGbPnn3Isvz8/CYrz7jehTqu7LonSoBx1tq3Dlo+HUiw1l5Wa/0EYB9QxYGw\nELL/9yrgJ9baxYcpZzCwgpthy2NbSE9IB2DXLkhLgwUL4KKL6lxtERGRVmPlypUMGTIEYIi1ts5X\nK9ZFvcY0WGsrgRXAudXLjOtvOBf4/DCbFAD9gIHAgP3/ngfW7f/9i2OVefC9JzSFtIiIiP80pHvi\nSWC6MWYFsBx3NUU0MB3AGPNHIM1aO2n/IMm1B29sjNkDlFlrM+pS2MFjGhQaRERE/KfeocFaO2f/\nnAwPAe2Bb4DR1trs/aukAp0bq4IKDSIiIoGhQQMhrbXTgGlHeO76Y2z7e+px6WXt0GAMJCbWdWsR\nERFpLAF/74nQkAO5JjfXBQaPx48VEhERaaUCOjSEekI5eF4HzdEgIiLiPwEdGsJDNLGTiIhIoAjo\n0BDmCTvkse47ISIi4j+BHRpCDg0NamkQERHxn4AODQcPggSFBhEREX8K6NBQu3tCoUFERMR/Ajs0\nHNQ9Ya3GNIiIiPhTQIeG8NADV08UFEBVlUKDiIiIvwR0aDi4paF6Cum2bf1UGRERkVYuoEND7dkg\nQS0NIiIi/hLQoeHggZAKDSIiIv4V0KEh1KilQUREJFAEdGio3dIQEQHR0X6skIiISCsW0KHBYw7c\nzrJ6joaD7l8lIiIizSigQ0Oo50D3hOZoEBER8a+ADg2Ha2kQERER/wjo0HDwJZf79kGbNn6sjIiI\nSCsXNKGhoADi4/1YGRERkVYuoEPDwd0TCg0iIiL+FdCh4eCWhsJCiIvzY2VERERauYAODWppEBER\nCRyBHRpCXGiwVi0NIiIi/hbQoaG6e6K83N0WWy0NIiIi/hMUoaGgwD1WS4OIiIj/BEVoKCx0j9XS\nICIi4j8BHRqqB0KqpUFERMT/Ajs07B8IqZYGERER/wvo0KAxDSIiIoEjoEODWhpEREQCR0CHhoNb\nGkJCIDrazxUSERFpxQI7NJgDV0/ExYExfq6QiIhIKxbQoaG6e6KgQOMZRERE/C2gQ8PB8zRoPIOI\niIh/BXRoUEuDiIhI4Ajs0GAOXD2hlgYRERH/CujQcPDVE2ppEBER8a+ADg0Hz9OglgYRERH/CujQ\noJYGERGRwBEUoUEtDSIiIv4X0KHh4LtcqqVBRETEvwI6NISGhGKtWhpEREQCQUCHBo/xUFYGVVVq\naRAREfG3gA4NoZ5Qiorc7woNIiIi/hXQocFjPDWhITbWv3URERFp7QI6NISGhCo0iIiIBAiFBhER\nEamTgA4NHuOhsND9rjENIiIi/hXQoeHggZBqaRAREfGvgA4NGggpIiISOAI7NIS40BAWBuHh/q6N\niIhI6xbakI2MMbcDvwJSgVXAndbaL4+w7mXAL4CBQASwBnjQWvv+MSu3fyCkWhlEROpm69at5OTk\n+Lsa0oSSk5NJT0/3S9n1Dg3GmAnAE8DNwHJgMvCeMeZEa+3h/lLPAt4H/h+QB9wALDDGnGatXXXU\nyplQCgs1CFJEpC62bt1Knz59KCkp8XdVpAlFR0eTkZHhl+DQkJaGycAL1tqZAMaYW4ExuDDwWO2V\nrbWTay36jTHmUuBiXCvFEVV3T6ilQUTk2HJycigpKeHll1+mT58+/q6ONIGMjAyuueYacnJyAj80\nGGPCgCHAo9XLrLXWGPMhcEYd92GAOGBvHdZVaBARqac+ffowePBgf1dDWqD6DoRMBjzA7lrLd+PG\nN9TFvUAMMKcuKys0iIiIBIYGDYRsKGPMVcBvgUuOMP7hEJMnT2b9+gQALrnELZs4cSITJ05swlqK\niIgEh9mzZzN79uxDluXn5zdZefUNDTmAF2hfa3l7IOtoGxpjfgb8DbjCWruoLoU99dRT3HPPYDp1\ngpdfrmdNRUREWrjDfZFeuXIlQ4YMaZLy6tU9Ya2tBFYA51Yv2z9G4Vzg8yNtZ4yZCPwD+Jm19t36\nlKnuCRERkcDQkO6JJ4HpxpgVHLjkMhqYDmCM+SOQZq2dtP/xVfufuwv40hhT3UpRaq0tOFZhCg0i\nIiKBod6hwVo7xxiTDDyE65b4Bhhtrc3ev0oq0PmgTW7CDZ786/5/1WbgLtM8KoUGERGRwNCggZDW\n2mnAtCM8d32tx6MaUka1wkKFBhERkUAQ0PeesNa1NGhGSBEREf8L6NBQXg4+n1oaRERau61bt3Lb\nbbfRu3dvoqOjSU5O5sorr2TLli0/Wjc/P5/JkyfTrVs3IiMj6dy5M5MmTWLv3gNzCpaXl/Pggw/S\nq1cvoqKiSEtLY9y4cWzevLk5X1bQadZ5GuqrtNT9VGgQEWndvvzyS5YtW8bEiRPp1KkTmZmZTJs2\njVGjRrF27VoiIyMBKC4uZvjw4axfv54bb7yRQYMGkZOTw1tvvcX27dtp27YtPp+PMWPGsGjRIiZO\nnMjdd99NYWEhH3zwAatXr6Zbt25+frWBK6BDQ/U9VxQaRERat4suuohx48Ydsuziiy9m6NChzJ07\nl6uvvhqAxx57jLVr1zJ//nwuqZ4VELj//vtrfp8xYwYfffQRTz/9NHfddVfN8ilTpjTxqwh+Cg0i\nIq1USQmsW9e0ZfTuDdHRx7+fiIiImt+rqqooKCige/fuJCYmsnLlyprQMG/ePAYMGHBIYKht3rx5\npKSkcMcddxx/xVqZoAgNGggpItL41q2DJpo4sMaKFdAY984qKyvj0UcfZfr06ezYsQNrLeBubHjw\ntMmbNm3iiiuuOOq+Nm3aRK9evQgJCehhfQEpKEKDWhpERBpf797upN7UZTSGO+64gxkzZjB58mSG\nDh1KQkICxhgmTJiAz+drnELkmAI6NGggpIhI04mObpxWgOYwd+5crrvuOh577LGaZeXl5eTl5R2y\nXo8ePVi9evVR99WjRw+WL1+O1+vF4/E0SX1bqoBumykudj8VGkREWjePx/OjFoWpU6fi9XoPWTZu\n3DhWrVrFm2++ecR9jRs3juzsbJ599tkmqWtLFtAtDcXFEBEB4eH+romIiPjTRRddxEsvvUR8fDx9\n+/Zl6dKlLFy4kOTk5EPWu/fee3njjTcYP348119/PUOGDCE3N5cFCxbwwgsv0L9/f6699lpmzpzJ\nPffcwxdffMGIESMoKipi4cKF3H777Vx88cV+epWBL+BDQ3y8v2shIiL+NnXqVEJDQ5k1axZlZWUM\nHz6cDz/8kNGjR+NutuzExMTw2Wef8cADDzB//nxmzpxJu3btOO+88+jUqRMAISEhvPPOOzzyyCPM\nmjWLefPmkZSUxIgRI+jfv7+/XmJQUGgQEZGAFx8fz4svvvij5T/88MOPliUmJvLMM8/wzDPPHHF/\nERERPPTQQzz00EONWs+WLuDHNCg0iIiIBIaADw2ao0FERCQwBHxoUEuDiIhIYFBoEBERkTpRaBAR\nEZE6CejQUFSkMQ0iIiKBIqBDg1oaREREAkdAh4aSEoUGERGRQBHQoaG8XKFBREQkUAR0aACNaRAR\nEQkUAR8a1NIgIiISGBQaREREpE4UGkREpNWZPn06ISEhbN261d9VCSoKDSIi0uoYYw65pbbUTcCH\nBg2EFBERCQwBHxpiY/1dAxEREYEADw3R0RAS0DUUEZHmMHfuXEJCQvj0009/9NwLL7xASEgIa9eu\n5bvvvuO6666jR48eREVF0aFDB2688Ub27t173HXYunUrt912G7179yY6Oprk5GSuvPJKtmzZ8qN1\n8/PzmTx5Mt26dSMyMpLOnTszadKkQ+pRXl7Ogw8+SK9evYiKiiItLY1x48axefPm465rUwn1dwWO\nJibG3zUQEZFAMGbMGGJjY5kzZw4jRow45Lk5c+bQv39/+vbty5NPPklmZiY33HADqamprFmzhhde\neIG1a9eydOnS46rDl19+ybJly5g4cSKdOnUiMzOTadOmMWrUKNauXUtkZCQAxcXFDB8+nPXr13Pj\njTcyaNAgcnJyeOutt9i+fTtt27bF5/MxZswYFi1axMSJE7n77rspLCzkgw8+YPXq1XTr1u246tpU\nFBpERFqpksoS1uWsa9Iyeif3Jjos+rj3ExkZycUXX8wbb7zB1KlTawYx7t69m48//piHHnoIgNtv\nv5177rnnkG1PP/10rrrqKpYsWcKwYcMaXIeLLrqIcePGHbLs4osvZujQocydO5err74agMcee4y1\na9cyf/58Lrnkkpp177///prfZ8yYwUcffcTTTz/NXXfdVbN8ypQpDa5fc1BoEBFppdblrGPI34Y0\naRkrbl7B4A6DG2VfEyZM4NVXX2Xx4sWMGjUKgNdffx1rLVdeeSUAERERNeuXl5dTVFTE6aefjrWW\nlStXHldoOHjfVVVVFBQU0L17dxITE1m5cmVNaJg3bx4DBgw4JDDUNm/ePFJSUrjjjjsaXB9/UGgQ\nEWmleif3ZsXNK5q8jMby05/+lPj4eF577bWa0DBnzhwGDhzICSecAMC+fft48MEHee2119izZ0/N\ntsYY8vPzj6v8srIyHn30UaZPn86OHTuw1h5235s2beKKK6446r42bdpEr169CAmygXsBHRo0R4OI\nSNOJDotutFaA5hAeHs7YsWOZP38+06ZNY9euXSxZsoQ//elPNeuMHz+eZcuWMWXKFAYMGEBsbCw+\nn4/Ro0fj8/mOq/w77riDGTNmMHnyZIYOHUpCQgLGGCZMmHDc+w4WAR0a2rb1dw1ERCSQTJgwgZkz\nZ/yU9ewAAAo4SURBVLJw4ULWrFkDUNM1kZeXx0cffcQf/vAHfvOb39Rss3HjxkYpe+7cuVx33XU8\n9thjNcvKy8vJy8s7ZL0ePXqwevXqo+6rR48eLF++HK/Xi8fjaZT6NYeAbhdp08bfNRARkUBy3nnn\n0aZNG1599VXmzJnDaaedRpcuXQBqTr61v/U/9dRTjTL7o8fj+dG+p06ditfrPWTZuHHjWLVqFW++\n+eYR9zVu3Diys7N59tlnj7tezUktDSIiEjRCQ0O5/PLLefXVVykpKeGJJ56oeS4uLo6zzjqLxx57\njIqKCjp27Mj7779PZmZmzfiD43HRRRfx0ksvER8fT9++fVm6dCkLFy4kOTn5kPXuvfde3njjDcaP\nH8/111/PkCFDyM3NZcGCBbzwwgv079+fa6+9lpkzZ3LPPffwxRdfMGLECIqKili4cCG33347F198\n8XHXtykoNIiISFCZMGEC//jHPwgJCWH8+PGHPDd79mzuvPNOpk2bhrWW0aNH884775CWlnbcrQ1T\np04lNDSUWbNmUVZWxvDhw/nwww8ZPXr0IfuOiYnhs88+44EHHmD+/PnMnDmTdu3acd5559GpUycA\nQkJCeOedd3jkkUeYNWsW8+bNIykpiREjRtC/f//jqmdTMo2RvhqbMWYwsOLFF1dw443BM0hHRMSf\nVq5cyZAhQ1ixYgWDB+uzsyWqy3tcvQ4wxFq7sjHLD+gxDWppEBERCRzqnhARkVatuLiYoqKio66T\nkpISdHMqNIWADg26w6WIiDS1P//5z/z+978/4vPGGDZv3kx6enoz1iowBXRoaIQrZERERI5q0qRJ\nP7oJVm2pqanNVJvAFtChQUREpKl17dqVrl27+rsaQUEdNCIiIlInCg0iIiJSJwoNIiIiUica0yAi\n0sJkZGT4uwrSRPz93io0iIi0EMnJyURHR3PNNdf4uyrShKKjo390v4vmotAgItJCpKenk5GRQU5O\njr+rIk0oOTnZb3NGKDQEuNmzZzNx4kR/VyMg6Fg4Og6OjsMBBx+L9PT0VjsJkf4mml6DBkIaY243\nxmw2xpQaY5YZY049xvpnG2NWGGPKjDH/v717i5WrquM4/v2V9AKYauTSg7EWpFpCIKglaJVLvYNE\niNFUA0nxEg00xshLifGhhAdJNV4QqZAQUKPUIF7SGK5eEi8UCBSIqC2mF1FqG0FzSmzBUv4+rHXC\nPrsz0z3HmdnTvX+fZB5m9prpWr/zP2dW16w9+0lJl82su+2zfv36urswNpxF4hwS5/AyZ5E4h+Hr\ne9Ig6aPAV4E1wJuBx4F7JHX8gEXSicDPgV8CZwDXATdLeu/MumxmZmZ1mMlKw5XATRHxvYjYDFwO\n7AU+2aX9FcC2iFgdEVsi4gbgjvw6ZmZmdpjoa9IgaTawlLRqAEBEBPALYFmXp70tHy+6p0d7MzMz\nG0P9boQ8FjgC2F16fDewpMtzJrq0ny9pbkS80OE586D+81HHweTkJJs2baq7G2PBWSTOIXEOL3MW\niXNICu+d8wb92koLBRUbSycATwPLIuLBwuNrgXMj4qDVA0lbgFsiYm3hsQtI+xyO6jRpkHQJ8IN+\nBmJmZmbTXBoRtw3yBftdaXgGOAAsKD2+ANjV5Tm7urTf02WVAdLHF5cCO4Dn++yjmZlZm80DTiS9\nlw5UX5OGiNgv6RHg3cAGAEnK97/Z5WkbgQtKj70vP97t33kWGOjsyMzMrEXuH8aLzuTsia8Bn5a0\nUtIpwI3AUcB3ACRdK+m7hfY3Aq+XtFbSEkmrgI/k1zEzM7PDRN/fCBkRt+fvZLiG9DHDY8D7I+Kf\nuckEsLDQfoekC4GvA58D/g58KiLKZ1SYmZnZGOtrI6SZmZm114y+RtrMzMzax5MGMzMzq2TsJg39\nXgzrcCdpjaSXSrc/ldpcI2mnpL2S7pO0uK7+DpKkcyRtkPR0HvdFHdr0HLukuZJukPSMpOck3SHp\n+NGN4v93qBwk3dqhRu4stWlCDl+Q9JCkPZJ2S/qppDd2aNeGmjhkFm2oC0mXS3pc0mS+3S/p/FKb\nNtRDzxxGWQtjNWlQnxfDapAnSJtKJ/Lt7KkDkq4CPgt8BjgL+A8pkzk19HPQjiZtpF0FHLS5puLY\nvwFcCHwYOBd4DfDj4XZ74HrmkN3F9BopX/+3CTmcA1wPvBV4DzAbuFfSkVMNWlQTh8wia3pd/A24\nCngL6RIGvwI2SDoVWlUPPXPIRlMLETE2N+AB4LrCfZHOtlhdd9+GOOY1wKYex3cCVxbuzwf2ASvq\n7vuAc3gJuKifsef7LwAfKrRZkl/rrLrHNMAcbgV+0uM5jcshj+HYPIaz21wTPbJoa108C3yizfXQ\nIYeR1cLYrDRoZhfDaoo35KXprZK+L2khgKSTSDPGYiZ7gAdpeCYVx34m6bThYpstwFM0L5/leZl6\ns6R1kl5dOLaUZubwKtLKy7+g9TUxLYuC1tSFpFmSPgbMBX7T1noo51A4NJJa6Pt7GoZoJhfDaoIH\ngI8DW4ATgKtJvxCnkX4hgs6ZTIyui7WoMvYFwH/zH4pubZrgLtIy4nbgZOBa4E5Jy/LEeoKG5SBJ\npOXU30XE1B6fVtZElyygJXWR/xZuJH018l7SKsJWSctoUT10yyEfHlktjNOkoZUiovjd4E9Iegj4\nK7AC2FxPr2ycRMTthbt/lPQHYCuwHPh1LZ0avnXAqcA76u7IGOiYRYvqYjNwBvBK0rcJ/1DSefV2\nqRYdc4iIR0dZC2Pz8QQzuxhW40TEJPAksJg0btHOTKqMfRcwR9L8Hm0aJyK2k35fpnaJNyoHSd8C\nPgAsj4h/FA61riZ6ZHGQptZFRLwYEdvym+MXSR8/XEHL6qFHDp3aDq0WxmbSEBH7gamLYQHTLoY1\nlAtvjCNJryD9oHfmH/wupmcyn7SjutGZVBz7I8CLpTZLgNfR44JohztJrwWOAabeRBqTQ36TvBh4\nZ0Q8VTzWtprolUWX9o2ti5JZwBFtq4cOZpE+0j/IUGuh7h2gpR2eK0if1awETgFuIu0QPa7uvg1x\nzF8hnf6yCHg7cB/pc6Zj8vHVOYMPAqcDPwP+Asypu+8DGPvRpOW2N5F28X4+319YdeykpdvtpGW4\npcDvgd/WPbZB5ZCPfZn0h3BR/qV/GPgzMLthOawD/k063XBB4Tav0KYtNdEzi7bUBfClnMEi4DTS\nZ/X7SROpNtVD1xxGXQu1h9EhnFXADtJpMxuBM+vu05DHu550Wuk+0k7W24CTSm2uJp1atJd0ffTF\ndfd7QGM/j/QmeaB0u6Xq2Ek7iK8nLcU9B/wIOL7usQ0qB9Kmp7tJ/6N6HtgGfJvSRLohOXTK4ACw\nstSuDTXRM4u21AVwcx7bvjzWe4F3tbAeuuYw6lrwBavMzMyskrHZ02BmZmbjzZMGMzMzq8STBjMz\nM6vEkwYzMzOrxJMGMzMzq8STBjMzM6vEkwYzMzOrxJMGMzMzq8STBjMzM6vEkwYzMzOrxJMGMzMz\nq+R/LevMcuEJrHgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c0ab588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlin = np.arange(323)\n",
    "plt.plot(xlin, hist.history['acc'])\n",
    "plt.plot(xlin, hist.history['val_acc'])\n",
    "plt.legend(['acc', 'val_acc'], loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
